{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in and preprocess Datasets (Fantasy, Combine, Advanced Statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fantasy Data (trailing 10 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Fantasy data from Pro Football Reference\n",
    "\n",
    "years_for_pfr_data = ['2021',\n",
    "                    '2020',\n",
    "                    '2019',\n",
    "                    '2018',\n",
    "                    '2017',\n",
    "                    '2016',\n",
    "                    '2015',\n",
    "                    '2014',\n",
    "                    '2013',\n",
    "                    '2012',\n",
    "                    ]\n",
    "\n",
    "fantasy_dfs = []\n",
    "for year in years_for_pfr_data: \n",
    "    link = \"https://www.pro-football-reference.com/years/\" + year + \"/fantasy.htm\" \n",
    "    df = pd.read_html(link)[0]\n",
    "    df['Year'] = year\n",
    "    fantasy_dfs.append(df)\n",
    "    \n",
    "fantasy_df = pd.concat(fantasy_dfs).reset_index(drop=True)\n",
    "\n",
    "# Flatten dataframe\n",
    "fantasy_df.columns = fantasy_df.columns.get_level_values(0) + '_' +  fantasy_df.columns.get_level_values(1)\n",
    "\n",
    "## Preprocess data\n",
    "# Rename Columns\n",
    "new_col_names = {'Unnamed: 0_level_0_Rk': 'Rank',\n",
    "        'Unnamed: 1_level_0_Player': 'Player',\n",
    "        'Unnamed: 2_level_0_Tm': 'Team',\n",
    "        'Unnamed: 3_level_0_FantPos': 'Position',\n",
    "        'Unnamed: 4_level_0_Age': 'Age',\n",
    "        'Year_': 'Year'}\n",
    "        \n",
    "fantasy_df.rename(columns=new_col_names, inplace=True)\n",
    "\n",
    "# Drop rows where column names are printed again (formatting issue w/ PFR website)\n",
    "fantasy_df = fantasy_df[~fantasy_df['Rank'].isin(['Rk'])]\n",
    "\n",
    "# Drop rows where Position is null (formatting issue w/ PFR website)\n",
    "fantasy_df = fantasy_df[fantasy_df['Position'].notna()]\n",
    "\n",
    "# Clean Player Name Column\n",
    "fantasy_df['Player'] = fantasy_df['Player'].str.strip('*+')\n",
    "\n",
    "# Fill NaN cells with 0\n",
    "fantasy_df = fantasy_df.fillna(0)\n",
    "\n",
    "# Rank Overall Fantasy Rank by Year (All values weren't filled in initally, must be added to dataset in place of zeros)\n",
    "# ...\n",
    "\n",
    "# Update Datatypes for columns\n",
    "convert_dtype_dict = {'Rank': int,\n",
    "                'Player': str,\n",
    "                'Team': str,\n",
    "                'Position': str,\n",
    "                'Age': int,\n",
    "                'Games_G': int,\n",
    "                'Games_GS': int,\n",
    "                'Passing_Cmp': int,\n",
    "                'Passing_Att': int,\n",
    "                'Passing_Yds': int,\n",
    "                'Passing_TD': int,\n",
    "                'Passing_Int': int,\n",
    "                'Rushing_Att': int,\n",
    "                'Rushing_Yds': int,\n",
    "                'Rushing_Y/A': float,\n",
    "                'Rushing_TD': int,\n",
    "                'Receiving_Tgt': int,\n",
    "                'Receiving_Rec': int,\n",
    "                'Receiving_Yds': int,\n",
    "                'Receiving_Y/R': float,\n",
    "                'Receiving_TD': int,\n",
    "                'Fumbles_Fmb': int,\n",
    "                'Fumbles_FL': int,\n",
    "                'Scoring_TD': int,\n",
    "                'Scoring_2PM': int,\n",
    "                'Scoring_2PP': int,\n",
    "                'Fantasy_FantPt': int,\n",
    "                'Fantasy_PPR': float,\n",
    "                'Fantasy_DKPt': float,\n",
    "                'Fantasy_FDPt': float,\n",
    "                'Fantasy_VBD': float,\n",
    "                'Fantasy_PosRank': int,\n",
    "                'Fantasy_OvRank': int,\n",
    "                'Year': str\n",
    "                }\n",
    " \n",
    "fantasy_df = fantasy_df.astype(convert_dtype_dict)\n",
    "\n",
    "# shift column 'Year' to first position\n",
    "first_column = fantasy_df.pop('Year')\n",
    "  \n",
    "# insert column at front of df\n",
    "fantasy_df.insert(0, 'Year', first_column)\n",
    "\n",
    "# Uncomment to Save dataset as flatfile (if desired)\n",
    "#fantasy_df.to_csv('data/pfr_10yr_data_2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Analytics from PFR (trailing 10 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Passing Data\n",
    "years_for_pfr_data = ['2021',\n",
    "                    '2020',\n",
    "                    '2019',\n",
    "                    '2018',\n",
    "                    '2017',\n",
    "                    '2016',\n",
    "                    '2015',\n",
    "                    '2014',\n",
    "                    '2013',\n",
    "                    '2012',\n",
    "                    ]\n",
    "\n",
    "passing_dfs = []\n",
    "for year in years_for_pfr_data: \n",
    "    link = \"https://www.pro-football-reference.com/years/\" + year + \"/passing.htm\" \n",
    "    df = pd.read_html(link)[0]\n",
    "    df['Year'] = year\n",
    "    passing_dfs.append(df)\n",
    "    \n",
    "passing_df = pd.concat(passing_dfs).reset_index(drop=True)\n",
    "\n",
    "# Rename Columns\n",
    "new_col_names = {'Rk': 'Rank',\n",
    "        'Att': 'Passing_Att',\n",
    "        'TD%': 'Passing_TD%',\n",
    "        'Int%': 'Passing_Int%',\n",
    "        '1D': 'Passing_1D',\n",
    "        'Lng': 'Passing_Lng',\n",
    "        'Y/A': 'Passing_Y/A',\n",
    "        'AY/A': 'Passing_AY/A',\n",
    "        'Y/C': 'Passing_Y/C',\n",
    "        'Y/G': 'Passing_Y/G',\n",
    "        'Rate': 'Passing_Rate',\n",
    "        'QBR': 'Passing_QBR',\n",
    "        'Sk': 'Passing_Sk',\n",
    "        'Sk%': 'Passing_Sk%',\n",
    "        'NY/A': 'Passing_NY/A',\n",
    "        'ANY/A': 'Passing_ANY/A'}\n",
    "        \n",
    "passing_df.rename(columns=new_col_names, inplace=True)\n",
    "\n",
    "# Drop rows where column names are printed again (formatting issue w/ PFR website)\n",
    "passing_df = passing_df[~passing_df['Rank'].isin(['Rk'])]\n",
    "\n",
    "# Clean Player Name Column\n",
    "passing_df['Player'] = passing_df['Player'].str.strip('*+')\n",
    "\n",
    "# Update Datatypes for columns\n",
    "convert_dtype_dict = {'Player': str,\n",
    "                'Passing_Att': int,\n",
    "                'Passing_TD%': float,\n",
    "                'Passing_Int%': float,\n",
    "                'Passing_1D': int,\n",
    "                'Passing_Lng': int,\n",
    "                'Passing_Y/A': float,\n",
    "                'Passing_AY/A': float,\n",
    "                'Passing_Y/C': float,\n",
    "                'Passing_Y/G': float,\n",
    "                'Passing_Rate': float,\n",
    "                'Passing_QBR': float,\n",
    "                'Passing_Sk': str,\n",
    "                'Passing_Sk%': float,\n",
    "                'Passing_NY/A': float,\n",
    "                'Passing_ANY/A': float\n",
    "                }\n",
    "passing_df = passing_df.astype(convert_dtype_dict)\n",
    "\n",
    "# Downselect rows to players that threw 20 or more passes\n",
    "passing_df = passing_df[passing_df['Passing_Att'] >= 20]\n",
    "\n",
    "# Downselect columns\n",
    "passing_df = passing_df[['Player','Passing_TD%','Passing_Int%','Passing_1D','Passing_Lng','Passing_Y/A','Passing_AY/A','Passing_Y/C','Passing_Y/G','Passing_Rate','Passing_QBR','Passing_Sk','Passing_Sk%','Passing_NY/A','Passing_ANY/A','Year']]\n",
    "\n",
    "# Uncomment to Save dataset as flatfile (if desired)\n",
    "passing_df.to_csv('data/pfr_10yr_passing_data_2022.csv')\n",
    "\n",
    "\n",
    "## Rushing Data\n",
    "rushing_dfs = []\n",
    "for year in years_for_pfr_data: \n",
    "    link = \"https://www.pro-football-reference.com/years/\" + year + \"/rushing.htm\" \n",
    "    df = pd.read_html(link)[0]\n",
    "    df['Year'] = year\n",
    "    rushing_dfs.append(df)\n",
    "    \n",
    "rushing_df = pd.concat(rushing_dfs).reset_index(drop=True)\n",
    "\n",
    "# Flatten dataframe\n",
    "rushing_df.columns = rushing_df.columns.get_level_values(0) + '_' +  rushing_df.columns.get_level_values(1)\n",
    "\n",
    "# Rename Columns\n",
    "new_col_names = {'Unnamed: 0_level_0_Rk': 'Rank',\n",
    "        'Unnamed: 1_level_0_Player': 'Player',\n",
    "        'Unnamed: 2_level_0_Tm': 'Team',\n",
    "        'Unnamed: 3_level_0_Age': 'Age',\n",
    "        'Unnamed: 4_level_0_Pos': 'Position',\n",
    "        'Unnamed: 14_level_0_Fmb': 'Rushing_Fumbles',\n",
    "        'Year_': 'Year'}\n",
    "        \n",
    "rushing_df.rename(columns=new_col_names, inplace=True)\n",
    "\n",
    "# Drop rows where column names are printed again (formatting issue w/ PFR website)\n",
    "rushing_df = rushing_df[~rushing_df['Rank'].isin(['Rk'])]\n",
    "\n",
    "# Clean Player Name Column\n",
    "rushing_df['Player'] = rushing_df['Player'].str.strip('*+')\n",
    "\n",
    "# Update Datatypes for columns\n",
    "convert_dtype_dict = {'Player': str,\n",
    "                'Rushing_1D': int,\n",
    "                'Rushing_Lng': int,\n",
    "                'Rushing_Y/A': float,\n",
    "                'Rushing_Y/G': float,\n",
    "                'Rushing_Fumbles': int,\n",
    "                'Year': str\n",
    "                }\n",
    "rushing_df = rushing_df.astype(convert_dtype_dict)\n",
    "\n",
    "# Downselect columns\n",
    "rushing_df = rushing_df[['Player','Rushing_1D','Rushing_Lng','Rushing_Y/A','Rushing_Y/G','Rushing_Fumbles','Year']]\n",
    "\n",
    "# Uncomment to Save dataset as flatfile (if desired)\n",
    "rushing_df.to_csv('data/pfr_10yr_rushing_data_2022.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Receiving Data\n",
    "receiving_dfs = []\n",
    "for year in years_for_pfr_data: \n",
    "    link = \"https://www.pro-football-reference.com/years/\" + year + \"/receiving.htm\" \n",
    "    df = pd.read_html(link)[0]\n",
    "    df['Year'] = year\n",
    "    receiving_dfs.append(df)\n",
    "    \n",
    "receiving_df = pd.concat(receiving_dfs).reset_index(drop=True)\n",
    "\n",
    "# Rename Columns\n",
    "new_col_names = {'Rk': 'Rank',\n",
    "        'Ctch%': 'Receiving_Ctch%',\n",
    "        'Lng': 'Receiving_Lng',\n",
    "        'Y/Tgt': 'Receiving_Y/Tgt',\n",
    "        'R/G': 'Receiving_R/G',\n",
    "        'Y/G': 'Receiving_Y/G',\n",
    "        'Year_': 'Year'}\n",
    "        \n",
    "receiving_df.rename(columns=new_col_names, inplace=True)\n",
    "\n",
    "# Drop rows where column names are printed again (formatting issue w/ PFR website)\n",
    "receiving_df = receiving_df[~receiving_df['Rank'].isin(['Rk'])]\n",
    "\n",
    "# Clean Player Name Column\n",
    "receiving_df['Player'] = receiving_df['Player'].str.strip('*+')\n",
    "# Clean Player Name Column\n",
    "receiving_df['Receiving_Ctch%'] = receiving_df['Receiving_Ctch%'].str.strip('%')\n",
    "\n",
    "# Update Datatypes for columns\n",
    "convert_dtype_dict = {'Player': str,\n",
    "                'Receiving_Ctch%': float,\n",
    "                'Receiving_Lng': int,\n",
    "                'Receiving_Y/Tgt': float,\n",
    "                'Receiving_R/G': float,\n",
    "                'Receiving_Y/G': float,\n",
    "                'Year': str\n",
    "                }\n",
    "receiving_df = receiving_df.astype(convert_dtype_dict)\n",
    "\n",
    "# Downselect columns\n",
    "#receiving_df = receiving_df[['Player','Receiving_Ctch%','Receiving_Lng','Receiving_Y/Tgt','Receiving_R/G','Receiving_Y/G','Year']]\n",
    "receiving_df = receiving_df[['Player','Receiving_Ctch%','Receiving_Lng','Receiving_Y/Tgt','Receiving_R/G','Year']]\n",
    "\n",
    "# Uncomment to Save dataset as flatfile (if desired)\n",
    "receiving_df.to_csv('data/pfr_10yr_receiving_data_2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Analytics from PFR (trailing 10 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add at later date...\n",
    "#https://www.pro-football-reference.com/years/2021/passing_advanced.htm\n",
    "#https://www.pro-football-reference.com/years/2021/rushing_advanced.htm\n",
    "#https://www.pro-football-reference.com/years/2021/receiving_advanced.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NFL Pre-Draft Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NFL Combine Data from Pro Football Reference\n",
    "\n",
    "years_for_pfr_data = ['2021',\n",
    "                    '2020',\n",
    "                    '2019',\n",
    "                    '2018',\n",
    "                    '2017',\n",
    "                    '2016',\n",
    "                    '2015',\n",
    "                    '2014',\n",
    "                    '2013',\n",
    "                    '2012',\n",
    "                    '2011',\n",
    "                    '2010',\n",
    "                    '2009',\n",
    "                    '2008',\n",
    "                    '2007',\n",
    "                    '2006',\n",
    "                    '2005',\n",
    "                    '2004',\n",
    "                    '2003',\n",
    "                    '2002',\n",
    "                    '2001',\n",
    "                    '2000',\n",
    "                    ]\n",
    "\n",
    "combine_dfs = []\n",
    "for year in years_for_pfr_data: \n",
    "    link = \"https://www.pro-football-reference.com/draft/\" + year + \"-combine.htm\" \n",
    "    df = pd.read_html(link)[0]\n",
    "    df['Combine_Year'] = year\n",
    "    combine_dfs.append(df)\n",
    "    \n",
    "combine_df = pd.concat(combine_dfs).reset_index(drop=True)\n",
    "\n",
    "## Preprocess Data\n",
    "\n",
    "# Drop rows where column names are printed again (formatting issue w/ PFR website)\n",
    "combine_df = combine_df[~combine_df['Player'].isin(['Player'])]\n",
    "\n",
    "# Drop Unnecessary columns\n",
    "combine_df = combine_df.drop(['College','Drafted (tm/rnd/yr)'], axis=1)\n",
    "\n",
    "# Fill NaN cells with 0\n",
    "combine_df = combine_df.fillna(0)\n",
    "# Fill NaN cells with median value of column\n",
    "#combine_df.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "\n",
    "# Update height column to usable number value\n",
    "ht_df = combine_df[\"Ht\"].str.split(\"-\", n = 1, expand = True)\n",
    "combine_df[\"Ft\"] = ht_df[0]\n",
    "combine_df = combine_df.fillna(0)\n",
    "combine_df[\"Ft\"] = combine_df[\"Ft\"].astype('int')\n",
    "combine_df[\"In\"] = ht_df[1]\n",
    "combine_df = combine_df.fillna(0)\n",
    "combine_df[\"In\"] = combine_df[\"In\"].astype('int')\n",
    "combine_df.drop(columns =[\"Ht\"], inplace = True)\n",
    "combine_df[\"Ht\"] = combine_df['Ft'] + combine_df['In']/12\n",
    "\n",
    "\n",
    "# Update Datatypes for columns\n",
    "convert_dtype_dict = {'Player': str,\n",
    "                'Pos':str,\n",
    "                'School': str,\n",
    "                'Ht': float,\n",
    "                'Wt': int,\n",
    "                '40yd': float,\n",
    "                'Vertical': float,\n",
    "                'Bench': int,\n",
    "                'Broad Jump': int,\n",
    "                '3Cone': float,\n",
    "                'Shuttle': float,\n",
    "                'Combine_Year': str,\n",
    "                }\n",
    "combine_df = combine_df.astype(convert_dtype_dict)\n",
    "\n",
    "combine_df.rename(columns={'Broad Jump': 'BroadJump', 'Pos':'Position'}, inplace=True)\n",
    "\n",
    "\n",
    "# Uncomment to Save combine dataset as flatfile (if desired)\n",
    "combine_df.to_csv('data/pfr_combine_data_2000_thru_2022.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fantasy Draft ADP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import flat files of fantasy mock draft adp data from Fantasy Football Calculator\n",
    "years_for_adp_data = ['2022',\n",
    "                    '2021',\n",
    "                    '2020',\n",
    "                    '2019',\n",
    "                    '2018',\n",
    "                    '2017',\n",
    "                    '2016',\n",
    "                    '2015',\n",
    "                    '2014',\n",
    "                    '2013',\n",
    "                    '2012'\n",
    "                    ]\n",
    "\n",
    "fantasy_draft_adp_dfs = []\n",
    "for year in years_for_adp_data: \n",
    "    filename = \"data/fantasy_draft_adp/draft_adp_\" + year + \".csv\" \n",
    "    df = pd.read_csv(filename)\n",
    "    df['Year'] = year\n",
    "    fantasy_draft_adp_dfs.append(df)\n",
    "    \n",
    "fantasy_draft_adp_df = pd.concat(fantasy_draft_adp_dfs).reset_index(drop=True)\n",
    "\n",
    "fantasy_draft_adp_df.rename(columns={'#':'ADP', 'Name':'Player', 'Overall':'AvgMockDraftPosition'}, inplace=True)\n",
    "\n",
    "fantasy_draft_adp_df\n",
    "fantasy_draft_adp_df_reduced = fantasy_draft_adp_df[['ADP','Player', 'AvgMockDraftPosition','Year']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join in other data specific to players (combine results, standard/advanced analytics, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Fantasy points data with passing data\n",
    "final_df = fantasy_df.merge(passing_df, how='left', on=['Player','Year'])\n",
    "\n",
    "# Merge DF with rushing data\n",
    "final_df = final_df.merge(rushing_df, how='left', on=['Player','Year'])\n",
    "\n",
    "# Merge DF with receiving data\n",
    "final_df = final_df.merge(receiving_df, how='left', on=['Player','Year'])\n",
    "\n",
    "# Merge Fantasy points data with combine data (fix later, pulling in name multiples)\n",
    "final_df = final_df.merge(combine_df, how='left', on=['Player','Position'])\n",
    "\n",
    "# Merge in Fantasy Draft ADP\n",
    "final_df = final_df.merge(fantasy_draft_adp_df_reduced, how='left', on=['Player','Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Second Josh Allen's combined data (Kentucky Josh)\n",
    "- lol\n",
    "- and also Mike Williams, Adrian Peterson, Alex Smith, and David Johnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are duplicates where players that share names with other players\n",
    "val_cnt_rows = final_df.Player.value_counts()\n",
    "val_cnt_rows.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Josh Allen for this study\n",
    "ja = final_df[((final_df['Player'] == 'Josh Allen') & (final_df['Combine_Year'] == \"2019\"))].index\n",
    "final_df = final_df.drop(ja)\n",
    "\n",
    "# One Mike Williams for this study\n",
    "mw = final_df[((final_df['Player'] == 'Mike Williams') & ((final_df['Combine_Year'] == \"2005\") | (final_df['Combine_Year'] == \"2010\")))].index\n",
    "final_df = final_df.drop(mw)\n",
    "\n",
    "# One Adrian Peterson for this study\n",
    "ap = final_df[((final_df['Player'] == 'Adrian Peterson') & (final_df['Combine_Year'] == \"2002\"))].index\n",
    "final_df = final_df.drop(ap)\n",
    "\n",
    "# One Alex Smith for this study\n",
    "als = final_df[((final_df['Player'] == 'Alex Smith') & (final_df['Position']==\"TE\"))].index\n",
    "final_df = final_df.drop(als)\n",
    "\n",
    "# One David Johnson for this study\n",
    "dj = final_df[((final_df['Player'] == 'David Johnson') & (final_df['Combine_Year'].isna()))].index\n",
    "final_df = final_df.drop(dj)\n",
    "dj_pt2 = final_df[((final_df['Player'] == 'David Johnson') & (final_df['Year'] == '2015') & ((final_df['Rushing_1D']  < 36) | (final_df['Receiving_Lng'] < 55)))].index\n",
    "final_df = final_df.drop(dj_pt2)\n",
    "dj_pt3 = final_df[((final_df['Player'] == 'David Johnson') & (final_df['Year'] == '2016') & (final_df['Receiving_Lng'] < 58))].index\n",
    "final_df = final_df.drop(dj_pt3)\n",
    "\n",
    "final_df = final_df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add additional custom parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add as necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save final_df as master dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated master dataframe\n",
    "final_df.to_csv('data/master_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number 1 ranked players from each fantasy season\n",
    "fantasy_df[fantasy_df['Fantasy_OvRank']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One players Fantasy Prodution during career\n",
    "fantasy_df[fantasy_df['Player']==\"Todd Gurley\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions located in this cell\n",
    "# Do one for pulling pfr data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Line plot of Age vs Fantasy PPR points (line by position)\n",
    "# Groupby on Data\n",
    "top_20_pos_rk_players = fantasy_df[fantasy_df['Fantasy_PosRank'] <= 20]\n",
    "age_pos_avg_ppr_gb = top_20_pos_rk_players.groupby(['Age','Position']).mean('Fantasy_PPR').reset_index()\n",
    "\n",
    "# Seaborn\n",
    "\n",
    "#age_pos_ppr_fig = sns.lineplot(data=age_pos_avg_ppr_gb, x='Age', y='Fantasy_PPR', hue='Position')\n",
    "#age_pos_ppr_fig.set_title('Average Fantasy Points (PPR) by Age and Position')\n",
    "#age_pos_ppr_fig.set_xlabel('Age')\n",
    "#age_pos_ppr_fig.set_ylabel('Fantasy Points')\n",
    "\n",
    "# Plotly\n",
    "age_pos_ppr_fig_px = px.line(age_pos_avg_ppr_gb, x=\"Age\", y=\"Fantasy_PPR\", color='Position', title='Average Fantasy Points (PPR) by Age and Position')\n",
    "plot_filename='plots/avg_points_by_age_position.html'\n",
    "age_pos_ppr_fig_px.write_html(plot_filename)\n",
    "age_pos_ppr_fig_px.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Line plot of count on top 20 players at each position by Age (line by position)\n",
    "# Groupby on Data\n",
    "top_20_pos_rk_players = fantasy_df[fantasy_df['Fantasy_PosRank'] <= 20]\n",
    "age_pos_count_gb = top_20_pos_rk_players.groupby(['Age','Position']).count().reset_index()\n",
    "\n",
    "# Plotly\n",
    "posrnk_age_count_plot_px = px.line(age_pos_count_gb, x=\"Age\", y=\"Rank\", color='Position', title='Number of Top 20 Position Rankings by Age and Position')\n",
    "posrnk_age_count_plot_px.update_layout(\n",
    "                   xaxis_title='Age',\n",
    "                   yaxis_title='Count of Top 20 Players')\n",
    "plot_filename='plots/top20_player_count_by_age_position.html'\n",
    "posrnk_age_count_plot_px.write_html(plot_filename)\n",
    "posrnk_age_count_plot_px.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scatter plot of Position Rank vs Fantasy PPR points (Color by Position)\n",
    "\n",
    "# Seaborn\n",
    "#posrnk_ppr_plot_sns = sns.scatterplot(data=final_df, x='Fantasy_PosRank', y='Fantasy_PPR', hue='Position')\n",
    "#posrnk_ppr_plot_sns.set_title('Average Fantasy Points (PPR) by Position')\n",
    "#posrnk_ppr_plot_sns.set_xlabel('Position Rank')\n",
    "#posrnk_ppr_plot_sns.set_ylabel('Fantasy Points')\n",
    "\n",
    "# Plotly\n",
    "posrnk_ppr_plot_px = px.scatter(fantasy_df, x=\"Fantasy_PosRank\", y=\"Fantasy_PPR\", color='Position', hover_data=['Player', 'Year'], title='Fantasy Points (PPR) by Position and Rank')\n",
    "plot_filename='plots/points_by_position.html'\n",
    "posrnk_ppr_plot_px.write_html(plot_filename)\n",
    "posrnk_ppr_plot_px.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of position vs Fantasy points\n",
    "# Seaborn\n",
    "#box_pos_ppr_sns = sns.boxplot(data=final_df, x='Position', y='Fantasy_PPR')\n",
    "\n",
    "# Plotly\n",
    "box_pos_ppr_px = px.box(fantasy_df, x=\"Position\", y=\"Fantasy_PPR\", hover_data=['Player', 'Year'], title='Fantasy Points by Position')\n",
    "plot_filename='plots/boxplot_points_by_position.html'\n",
    "box_pos_ppr_px.write_html(plot_filename)\n",
    "box_pos_ppr_px.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rbs_speed = final_df[(final_df['Position'] == 'RB') & (final_df['40yd'] > 0)]\n",
    "#rb_speed_ppr_px = px.scatter(rbs_speed, x='40yd', y='Fantasy_PPR', hover_data=['Player'])\n",
    "#rb_speed_ppr_px.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "qbs_speed = final_df[(final_df['Position'] == 'QB') & (final_df['40yd'] > 0)]\n",
    "rbs_speed = final_df[(final_df['Position'] == 'RB') & (final_df['40yd'] > 0)]\n",
    "wrs_speed = final_df[(final_df['Position'] == 'WR') & (final_df['40yd'] > 0)]\n",
    "tes_speed = final_df[(final_df['Position'] == 'TE') & (final_df['40yd'] > 0)]\n",
    "\n",
    "speed_and_pos_vs_points = make_subplots(rows=2, cols=2, subplot_titles=('Quarterback', 'Running Back', 'Wide Receiver', 'Tight End'))\n",
    "\n",
    "speed_and_pos_vs_points.add_trace(\n",
    "    go.Scatter(\n",
    "        x=qbs_speed['40yd'],\n",
    "        y=qbs_speed['Fantasy_PPR'],\n",
    "        mode='markers'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "speed_and_pos_vs_points.add_trace(\n",
    "    go.Scatter(\n",
    "        x=rbs_speed['40yd'],\n",
    "        y=rbs_speed['Fantasy_PPR'],\n",
    "        mode='markers'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "speed_and_pos_vs_points.add_trace(\n",
    "    go.Scatter(\n",
    "        x=wrs_speed['40yd'],\n",
    "        y=wrs_speed['Fantasy_PPR'],\n",
    "        mode='markers'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "speed_and_pos_vs_points.add_trace(\n",
    "    go.Scatter(\n",
    "        x=tes_speed['40yd'],\n",
    "        y=tes_speed['Fantasy_PPR'],\n",
    "        mode='markers'\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Update xaxis properties\n",
    "speed_and_pos_vs_points.update_xaxes(title_text=\"40-yd Dash time (secs)\", range=[4, 6], row=1, col=1)\n",
    "speed_and_pos_vs_points.update_xaxes(title_text=\"40-yd Dash time (secs)\", range=[4, 6], row=1, col=2)\n",
    "speed_and_pos_vs_points.update_xaxes(title_text=\"40-yd Dash time (secs)\", range=[4, 6], row=2, col=1)\n",
    "speed_and_pos_vs_points.update_xaxes(title_text=\"40-yd Dash time (secs)\", range=[4, 6], row=2, col=2)\n",
    "\n",
    "# Update yaxis properties\n",
    "speed_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=[0, 500], row=1, col=1)\n",
    "speed_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=[0, 500], row=1, col=2)\n",
    "speed_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=[0, 500], row=2, col=1)\n",
    "speed_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=[0, 500], row=2, col=2)\n",
    "\n",
    "speed_and_pos_vs_points.update_layout(title_text=\"Fantasy Points (PPR) vs 40-Time by Position\", height=600, showlegend=False)\n",
    "\n",
    "plot_filename='plots/speed_vs_points_and_position.html'\n",
    "speed_and_pos_vs_points.write_html(plot_filename)\n",
    "speed_and_pos_vs_points.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qbs_vert = final_df[(final_df['Position'] == 'QB') & (final_df['Vertical'] > 0)]\n",
    "rbs_vert = final_df[(final_df['Position'] == 'RB') & (final_df['Vertical'] > 0)]\n",
    "wrs_vert = final_df[(final_df['Position'] == 'WR') & (final_df['Vertical'] > 0)]\n",
    "tes_vert = final_df[(final_df['Position'] == 'TE') & (final_df['Vertical'] > 0)]\n",
    "\n",
    "vert_and_pos_vs_points = make_subplots(rows=2, cols=2, subplot_titles=('Quarterback', 'Running Back', 'Wide Receiver', 'Tight End'))\n",
    "\n",
    "vert_and_pos_vs_points.add_trace(\n",
    "    go.Scatter(\n",
    "        x=qbs_vert['Vertical'],\n",
    "        y=qbs_vert['Fantasy_PPR'],\n",
    "        mode='markers'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "vert_and_pos_vs_points.add_trace(\n",
    "    go.Scatter(\n",
    "        x=rbs_vert['Vertical'],\n",
    "        y=rbs_vert['Fantasy_PPR'],\n",
    "        mode='markers'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "vert_and_pos_vs_points.add_trace(\n",
    "    go.Scatter(\n",
    "        x=wrs_vert['Vertical'],\n",
    "        y=wrs_vert['Fantasy_PPR'],\n",
    "        mode='markers'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "vert_and_pos_vs_points.add_trace(\n",
    "    go.Scatter(\n",
    "        x=tes_vert['Vertical'],\n",
    "        y=tes_vert['Fantasy_PPR'],\n",
    "        mode='markers'\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Update xaxis properties\n",
    "vert_and_pos_vs_points.update_xaxes(title_text=\"Vertical Jump (inches)\", range=[10, 50], row=1, col=1)\n",
    "vert_and_pos_vs_points.update_xaxes(title_text=\"Vertical Jump (inches)\", range=[10, 50], row=1, col=2)\n",
    "vert_and_pos_vs_points.update_xaxes(title_text=\"Vertical Jump (inches)\", range=[10, 50], row=2, col=1)\n",
    "vert_and_pos_vs_points.update_xaxes(title_text=\"Vertical Jump (inches)\", range=[10, 50], row=2, col=2)\n",
    "\n",
    "# Update yaxis properties\n",
    "vert_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=[0, 500], row=1, col=1)\n",
    "vert_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=[0, 500], row=1, col=2)\n",
    "vert_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=[0, 500], row=2, col=1)\n",
    "vert_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=[0, 500], row=2, col=2)\n",
    "\n",
    "vert_and_pos_vs_points.update_layout(title_text=\"Fantasy Points (PPR) vs Vertical Jump by Position\", height=600, showlegend=False)\n",
    "\n",
    "plot_filename='plots/vert_vs_points_and_position.html'\n",
    "vert_and_pos_vs_points.write_html(plot_filename)\n",
    "vert_and_pos_vs_points.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pts_vs_combine_scatterplots(df, subplot_config, yaxis_range=[0,500]):\n",
    "    for plot in subplot_config['plots']:\n",
    "        print(\"Using \"+plot['args']['measurement']+\" for plot...\")\n",
    "        measure = plot['args']['measurement']\n",
    "        unit = plot['args']['units']\n",
    "        xrange = plot['args']['xrange']\n",
    "\n",
    "        qbs = df[(df['Position'] == 'QB') & (df[measure] > 0)]\n",
    "        rbs = df[(df['Position'] == 'RB') & (df[measure] > 0)]\n",
    "        wrs = df[(df['Position'] == 'WR') & (df[measure] > 0)]\n",
    "        tes = df[(df['Position'] == 'TE') & (df[measure] > 0)]\n",
    "\n",
    "        meas_and_pos_vs_points = make_subplots(rows=2, cols=2, subplot_titles=('Quarterback', 'Running Back', 'Wide Receiver', 'Tight End'))\n",
    "\n",
    "        meas_and_pos_vs_points.add_trace(\n",
    "            go.Scatter(\n",
    "                x=qbs[measure],\n",
    "                y=qbs['Fantasy_PPR'],\n",
    "                mode='markers'\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "        meas_and_pos_vs_points.add_trace(\n",
    "            go.Scatter(\n",
    "                x=rbs[measure],\n",
    "                y=rbs['Fantasy_PPR'],\n",
    "                mode='markers'\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "\n",
    "        meas_and_pos_vs_points.add_trace(\n",
    "            go.Scatter(\n",
    "                x=wrs[measure],\n",
    "                y=wrs['Fantasy_PPR'],\n",
    "                mode='markers'\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "\n",
    "        meas_and_pos_vs_points.add_trace(\n",
    "            go.Scatter(\n",
    "                x=tes[measure],\n",
    "                y=tes['Fantasy_PPR'],\n",
    "                mode='markers'\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "\n",
    "        # Update xaxis properties\n",
    "        x_title = str(measure)+' ('+str(unit)+')'\n",
    "        meas_and_pos_vs_points.update_xaxes(title_text=x_title, range=xrange, row=1, col=1)\n",
    "        meas_and_pos_vs_points.update_xaxes(title_text=x_title, range=xrange, row=1, col=2)\n",
    "        meas_and_pos_vs_points.update_xaxes(title_text=x_title, range=xrange, row=2, col=1)\n",
    "        meas_and_pos_vs_points.update_xaxes(title_text=x_title, range=xrange, row=2, col=2)\n",
    "\n",
    "        # Update yaxis properties\n",
    "        meas_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=yaxis_range, row=1, col=1)\n",
    "        meas_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=yaxis_range, row=1, col=2)\n",
    "        meas_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=yaxis_range, row=2, col=1)\n",
    "        meas_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=yaxis_range, row=2, col=2)\n",
    "\n",
    "        meas_and_pos_vs_points.update_layout(title_text=\"Fantasy Points (PPR) vs \"+str(measure)+\" by Position\", height=600, showlegend=False)\n",
    "\n",
    "        plot_filename='plots/'+str(measure)+'_vs_points_and_position.html'\n",
    "        meas_and_pos_vs_points.write_html(plot_filename)\n",
    "        print(\"Plot saved\")\n",
    "    print('')\n",
    "    print('Plots complete!')\n",
    "\n",
    "\n",
    "subplot_config = \\\n",
    "{\n",
    "    \"plots\":[\n",
    "        {\n",
    "            \"args\": {\n",
    "                \"measurement\":\"40yd\",\n",
    "                \"units\": 'secs',\n",
    "                \"xrange\": [4,6]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"args\": {\n",
    "                \"measurement\": \"Vertical\",\n",
    "                \"units\": 'inches',\n",
    "                \"xrange\": [20,50]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"args\": {\n",
    "                \"measurement\": \"Bench\",\n",
    "                \"units\": 'reps',\n",
    "                \"xrange\":[0,50]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"args\": {\n",
    "                \"measurement\": \"BroadJump\",\n",
    "                \"units\": 'inches',\n",
    "                \"xrange\": [80,150]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"args\": {\n",
    "                \"measurement\": \"3Cone\",\n",
    "                \"units\": 'secs',\n",
    "                \"xrange\": [6,9]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"args\": {\n",
    "                \"measurement\": \"Shuttle\",\n",
    "                \"units\": 'secs',\n",
    "                \"xrange\": [3.5,5.5]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "pts_vs_combine_scatterplots(final_df, subplot_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Dataset\n",
    "df = pd.read_csv('data/master_df.csv')\n",
    "\n",
    "# Separate Datasets by Position\n",
    "qbs = df[df['Position'] == 'QB']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = StandardScaler()\n",
    "#qb_reduced_df = qbs[['Age','Passing_TD%','Passing_Int%','Passing_1D','Passing_Lng','Passing_Y/A','Passing_AY/A','Passing_Y/C','Passing_Sk','Passing_Sk%','Passing_NY/A','Passing_ANY/A','Rushing_1D','Rushing_Lng','Rushing_Y/A_y','Fantasy_PPR']]\n",
    "#qb_reduced_df = qbs[['Age','Passing_TD%','Passing_Int%','Passing_Lng','Passing_Y/A','Passing_AY/A','Passing_Y/C','Passing_Sk','Passing_Sk%','Passing_NY/A','Passing_ANY/A','Rushing_Lng','Rushing_Y/A_y','Fantasy_PPR']]\n",
    "qb_reduced_df = qbs[['Age','Passing_TD%','Passing_Int%','Passing_Lng','Passing_Y/A','Passing_AY/A','Passing_Y/C','Passing_Sk%','Passing_NY/A','Passing_ANY/A','Rushing_Lng','Rushing_Y/A_y','Fantasy_PPR']]\n",
    "#qb_reduced_df = qb_reduced_df.dropna()\n",
    "qb_reduced_df.replace(0, np.nan, inplace=True)\n",
    "qb_reduced_df = qb_reduced_df.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "model.fit(qb_reduced_df)\n",
    "\n",
    "#qb_plt = sns.pairplot(qb_reduced_df)\n",
    "#plt.savefig('plots/qb_pairplot.png')\n",
    "qb_reduced_df.to_csv('data/qb_std_stats_no_1ds_or_sks.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Dataset\n",
    "df = pd.read_csv('data/master_df.csv')\n",
    "rbs = df[df['Position'] == 'RB']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = StandardScaler()\n",
    "#rb_reduced_df = rbs[['Age','Rushing_1D','Rushing_Lng','Rushing_Y/A_y','Receiving_Ctch%','Receiving_Lng','Receiving_Y/Tgt','Fantasy_PPR']]\n",
    "rb_reduced_df = rbs[['Age','Rushing_Fumbles','Rushing_Lng','Rushing_Y/A_y','Receiving_Ctch%','Receiving_Lng','Receiving_Y/Tgt','Fantasy_PPR']]\n",
    "#rb_reduced_df = rb_reduced_df.dropna()\n",
    "rb_reduced_df.replace(0, np.nan, inplace=True)\n",
    "rb_reduced_df = rb_reduced_df.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "model.fit(rb_reduced_df)\n",
    "rb_reduced_df.to_csv('data/rb_std_stats_no_1ds.csv')\n",
    "#rb_plt = sns.pairplot(rb_reduced_df)\n",
    "#plt.savefig('plots/rb_pairplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Dataset\n",
    "df = pd.read_csv('data/master_df.csv')\n",
    "\n",
    "wrs = df[df['Position'] == 'WR']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = StandardScaler()\n",
    "wr_reduced_df = wrs[['Age','Receiving_Ctch%','Receiving_Lng','Receiving_Y/Tgt','Fantasy_PPR']]\n",
    "#wr_reduced_df = wr_reduced_df.dropna()\n",
    "wr_reduced_df.replace(0, np.nan, inplace=True)\n",
    "wr_reduced_df = wr_reduced_df.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "model.fit(wr_reduced_df)\n",
    "\n",
    "wr_plt = sns.pairplot(wr_reduced_df)\n",
    "plt.savefig('plots/wr_pairplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Dataset\n",
    "df = pd.read_csv('data/master_df.csv')\n",
    "\n",
    "tes = df[df['Position'] == 'TE']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = StandardScaler()\n",
    "te_reduced_df = tes[['Age','Receiving_Ctch%','Receiving_Lng','Receiving_Y/Tgt','Fantasy_PPR']]\n",
    "#te_reduced_df = te_reduced_df.dropna()\n",
    "te_reduced_df.replace(0, np.nan, inplace=True)\n",
    "te_reduced_df = te_reduced_df.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "model.fit(te_reduced_df)\n",
    "\n",
    "te_plt = sns.pairplot(te_reduced_df)\n",
    "plt.savefig('plots/te_pairplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Dataset\n",
    "df = pd.read_csv('data/master_df.csv')\n",
    "\n",
    "# Separate Datasets by Position\n",
    "qbs = df[df['Position'] == 'QB']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = StandardScaler()\n",
    "qb_combine_df = qbs[['Ht','Wt','40yd','Vertical','Bench','BroadJump','3Cone','Shuttle','Combine_Year','Fantasy_PPR']]\n",
    "#qb_combine_df = qb_combine_df.dropna()\n",
    "qb_combine_df.replace(0, np.nan, inplace=True)\n",
    "qb_combine_df = qb_combine_df.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "model.fit(qb_combine_df)\n",
    "\n",
    "qb_combine_plt = sns.pairplot(qb_combine_df)\n",
    "plt.savefig('plots/qb_combine_pairplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Dataset\n",
    "df = pd.read_csv('data/master_df.csv')\n",
    "\n",
    "# Separate Datasets by Position\n",
    "rbs = df[df['Position'] == 'RB']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = StandardScaler()\n",
    "rb_combine_df = rbs[['Ht','Wt','40yd','Vertical','Bench','BroadJump','3Cone','Shuttle','Combine_Year','Fantasy_PPR']]\n",
    "#rb_combine_df = rb_combine_df.dropna()\n",
    "rb_combine_df.replace(0, np.nan, inplace=True)\n",
    "rb_combine_df = rb_combine_df.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "model.fit(rb_combine_df)\n",
    "\n",
    "rb_combine_plt = sns.pairplot(rb_combine_df)\n",
    "plt.savefig('plots/rb_combine_pairplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Dataset\n",
    "df = pd.read_csv('data/master_df.csv')\n",
    "\n",
    "# Separate Datasets by Position\n",
    "wrs = df[df['Position'] == 'WR']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = StandardScaler()\n",
    "wr_combine_df = wrs[['Ht','Wt','40yd','Vertical','Bench','BroadJump','3Cone','Shuttle','Combine_Year','Fantasy_PPR']]\n",
    "#wr_combine_df = wr_combine_df.dropna()\n",
    "wr_combine_df.replace(0, np.nan, inplace=True)\n",
    "wr_combine_df = wr_combine_df.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "model.fit(wr_combine_df)\n",
    "\n",
    "wr_combine_plt = sns.pairplot(wr_combine_df)\n",
    "plt.savefig('plots/wr_combine_pairplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Dataset\n",
    "df = pd.read_csv('data/master_df.csv')\n",
    "\n",
    "# Separate Datasets by Position\n",
    "tes = df[df['Position'] == 'TE']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = StandardScaler()\n",
    "te_combine_df = tes[['Ht','Wt','40yd','Vertical','Bench','BroadJump','3Cone','Shuttle','Combine_Year','Fantasy_PPR']]\n",
    "#te_combine_df = te_combine_df.dropna()\n",
    "te_combine_df.replace(0, np.nan, inplace=True)\n",
    "te_combine_df = te_combine_df.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "model.fit(te_combine_df)\n",
    "\n",
    "te_combine_plt = sns.pairplot(te_combine_df)\n",
    "plt.savefig('plots/te_combine_pairplot.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_reduced_df.to_csv('data/qb_std_stats.csv')\n",
    "rb_reduced_df.to_csv('data/rb_std_stats.csv')\n",
    "wr_reduced_df.to_csv('data/wr_std_stats.csv')\n",
    "te_reduced_df.to_csv('data/te_std_stats.csv')\n",
    "qb_combine_df.to_csv('data/qb_combine_stats.csv')\n",
    "rb_combine_df.to_csv('data/rb_combine_stats.csv')\n",
    "wr_combine_df.to_csv('data/wr_combine_stats.csv')\n",
    "te_combine_df.to_csv('data/te_combine_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_reduced_df_no_1ds = qbs[['Age','Passing_TD%','Passing_Int%','Passing_Lng','Passing_Y/A','Passing_AY/A','Passing_Y/C','Passing_Sk','Passing_Sk%','Passing_NY/A','Passing_ANY/A','Rushing_Lng','Rushing_Y/A_y','Fantasy_PPR']]\n",
    "qb_reduced_df_no_1ds.to_csv('data/qb_std_stats_no_1ds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/master_df.csv')\n",
    "arod_example_lag_data = df[df['Player'] == 'Aaron Rodgers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Index(...) must be called with a collection of some kind, '1Y' was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mattg\\Desktop\\Hobbies\\fantasy_football\\eda.ipynb Cell 46\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mattg/Desktop/Hobbies/fantasy_football/eda.ipynb#X63sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m year \u001b[39min\u001b[39;00m [\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m]:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mattg/Desktop/Hobbies/fantasy_football/eda.ipynb#X63sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     start \u001b[39m=\u001b[39m arod_example_lag_data[\u001b[39m'\u001b[39m\u001b[39mYear\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmax() \u001b[39m-\u001b[39m year\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mattg/Desktop/Hobbies/fantasy_football/eda.ipynb#X63sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     out\u001b[39m.\u001b[39mappend(arod_example_lag_data[start:]\u001b[39m.\u001b[39;49mgroupby(cols)\u001b[39m.\u001b[39;49mmean([\u001b[39m'\u001b[39;49m\u001b[39mFantasy_PPR\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39;49msqueeze()\u001b[39m.\u001b[39;49mrename(\u001b[39m\"\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39mY\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(year)))\n",
      "File \u001b[1;32mc:\\Users\\mattg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:5083\u001b[0m, in \u001b[0;36mDataFrame.rename\u001b[1;34m(self, mapper, index, columns, axis, copy, inplace, level, errors)\u001b[0m\n\u001b[0;32m   4964\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrename\u001b[39m(\n\u001b[0;32m   4965\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4966\u001b[0m     mapper: Renamer \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4974\u001b[0m     errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   4975\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4976\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4977\u001b[0m \u001b[39m    Alter axes labels.\u001b[39;00m\n\u001b[0;32m   4978\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5081\u001b[0m \u001b[39m    4  3  6\u001b[39;00m\n\u001b[0;32m   5082\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5083\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_rename(\n\u001b[0;32m   5084\u001b[0m         mapper\u001b[39m=\u001b[39;49mmapper,\n\u001b[0;32m   5085\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5086\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5087\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5088\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   5089\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5090\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5091\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5092\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mattg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:1145\u001b[0m, in \u001b[0;36mNDFrame._rename\u001b[1;34m(self, mapper, index, columns, axis, copy, inplace, level, errors)\u001b[0m\n\u001b[0;32m   1143\u001b[0m     indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39mget_level_values(level)\u001b[39m.\u001b[39mget_indexer_for(replacements)\n\u001b[0;32m   1144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1145\u001b[0m     indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49mget_indexer_for(replacements)\n\u001b[0;32m   1147\u001b[0m \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(indexer[indexer \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]):\n\u001b[0;32m   1148\u001b[0m     missing_labels \u001b[39m=\u001b[39m [\n\u001b[0;32m   1149\u001b[0m         label\n\u001b[0;32m   1150\u001b[0m         \u001b[39mfor\u001b[39;00m index, label \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(replacements)\n\u001b[0;32m   1151\u001b[0m         \u001b[39mif\u001b[39;00m indexer[index] \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m   1152\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\mattg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5764\u001b[0m, in \u001b[0;36mIndex.get_indexer_for\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m   5746\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5747\u001b[0m \u001b[39mGuaranteed return of an indexer even when non-unique.\u001b[39;00m\n\u001b[0;32m   5748\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5761\u001b[0m \u001b[39marray([0, 2])\u001b[39;00m\n\u001b[0;32m   5762\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5763\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 5764\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_indexer(target)\n\u001b[0;32m   5765\u001b[0m indexer, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_indexer_non_unique(target)\n\u001b[0;32m   5766\u001b[0m \u001b[39mreturn\u001b[39;00m indexer\n",
      "File \u001b[1;32mc:\\Users\\mattg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3716\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3706\u001b[0m \u001b[39m@Appender\u001b[39m(_index_shared_docs[\u001b[39m\"\u001b[39m\u001b[39mget_indexer\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m%\u001b[39m _index_doc_kwargs)\n\u001b[0;32m   3707\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   3708\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_indexer\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3713\u001b[0m     tolerance\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   3714\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m npt\u001b[39m.\u001b[39mNDArray[np\u001b[39m.\u001b[39mintp]:\n\u001b[0;32m   3715\u001b[0m     method \u001b[39m=\u001b[39m missing\u001b[39m.\u001b[39mclean_reindex_fill_method(method)\n\u001b[1;32m-> 3716\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_cast_listlike_indexer(target)\n\u001b[0;32m   3718\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[0;32m   3720\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n",
      "File \u001b[1;32mc:\\Users\\mattg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6297\u001b[0m, in \u001b[0;36mIndex._maybe_cast_listlike_indexer\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m   6293\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_maybe_cast_listlike_indexer\u001b[39m(\u001b[39mself\u001b[39m, target) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Index:\n\u001b[0;32m   6294\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   6295\u001b[0m \u001b[39m    Analogue to maybe_cast_indexer for get_indexer instead of get_loc.\u001b[39;00m\n\u001b[0;32m   6296\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6297\u001b[0m     \u001b[39mreturn\u001b[39;00m ensure_index(target)\n",
      "File \u001b[1;32mc:\\Users\\mattg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:7043\u001b[0m, in \u001b[0;36mensure_index\u001b[1;34m(index_like, copy)\u001b[0m\n\u001b[0;32m   7041\u001b[0m         \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39m_with_infer(index_like, copy\u001b[39m=\u001b[39mcopy, tupleize_cols\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   7042\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 7043\u001b[0m     \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39;49m_with_infer(index_like, copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\mattg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:680\u001b[0m, in \u001b[0;36mIndex._with_infer\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[0;32m    679\u001b[0m     warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m.*the Index constructor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m)\n\u001b[1;32m--> 680\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    682\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m _dtype_obj \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39m_is_multi:\n\u001b[0;32m    683\u001b[0m     \u001b[39m# error: Argument 1 to \"maybe_convert_objects\" has incompatible type\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     \u001b[39m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected\u001b[39;00m\n\u001b[0;32m    685\u001b[0m     \u001b[39m# \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m    686\u001b[0m     values \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmaybe_convert_objects(result\u001b[39m.\u001b[39m_values)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mattg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:508\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[1;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[39mreturn\u001b[39;00m klass\u001b[39m.\u001b[39m_simple_new(arr, name)\n\u001b[0;32m    507\u001b[0m \u001b[39melif\u001b[39;00m is_scalar(data):\n\u001b[1;32m--> 508\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_scalar_data_error(data)\n\u001b[0;32m    509\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(data, \u001b[39m\"\u001b[39m\u001b[39m__array__\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    510\u001b[0m     \u001b[39mreturn\u001b[39;00m Index(np\u001b[39m.\u001b[39masarray(data), dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy, name\u001b[39m=\u001b[39mname, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: Index(...) must be called with a collection of some kind, '1Y' was passed"
     ]
    }
   ],
   "source": [
    "for year in [2, 3, 5]:\n",
    "\n",
    "\n",
    "\n",
    "arod_example_lag_data\n",
    "\n",
    "cols = [\"Player\"]\n",
    "out = []\n",
    "for year in [1, 2, 3, 4]:\n",
    "    start = arod_example_lag_data['Year'].max() - year\n",
    "    out.append(arod_example_lag_data[start:].groupby(cols).mean(['Fantasy_PPR']).squeeze().rename(\"{}Y\".format(year)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattg\\AppData\\Local\\Temp\\ipykernel_1516\\1230464747.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  arod_example_lag_data[year_name] = grouped_data['Fantasy_PPR'][0]\n",
      "C:\\Users\\mattg\\AppData\\Local\\Temp\\ipykernel_1516\\1230464747.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  arod_example_lag_data[year_name] = grouped_data['Fantasy_PPR'][0]\n",
      "C:\\Users\\mattg\\AppData\\Local\\Temp\\ipykernel_1516\\1230464747.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  arod_example_lag_data[year_name] = grouped_data['Fantasy_PPR'][0]\n",
      "C:\\Users\\mattg\\AppData\\Local\\Temp\\ipykernel_1516\\1230464747.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  arod_example_lag_data[year_name] = grouped_data['Fantasy_PPR'][0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Position</th>\n",
       "      <th>Age</th>\n",
       "      <th>Games_G</th>\n",
       "      <th>Games_GS</th>\n",
       "      <th>Passing_Cmp</th>\n",
       "      <th>...</th>\n",
       "      <th>Combine_Year</th>\n",
       "      <th>Ft</th>\n",
       "      <th>In</th>\n",
       "      <th>Ht</th>\n",
       "      <th>ADP</th>\n",
       "      <th>AvgMockDraftPosition</th>\n",
       "      <th>2Y_avg</th>\n",
       "      <th>3Y_avg</th>\n",
       "      <th>4Y_avg</th>\n",
       "      <th>5Y_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2021</td>\n",
       "      <td>18</td>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>GNB</td>\n",
       "      <td>QB</td>\n",
       "      <td>38</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>366</td>\n",
       "      <td>...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>61.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>333.3</td>\n",
       "      <td>358.3</td>\n",
       "      <td>331.666667</td>\n",
       "      <td>326.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>606</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>GNB</td>\n",
       "      <td>QB</td>\n",
       "      <td>37</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>372</td>\n",
       "      <td>...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>96.0</td>\n",
       "      <td>94.3</td>\n",
       "      <td>333.3</td>\n",
       "      <td>358.3</td>\n",
       "      <td>331.666667</td>\n",
       "      <td>326.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>1235</td>\n",
       "      <td>2019</td>\n",
       "      <td>56</td>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>GNB</td>\n",
       "      <td>QB</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>353</td>\n",
       "      <td>...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.7</td>\n",
       "      <td>333.3</td>\n",
       "      <td>358.3</td>\n",
       "      <td>331.666667</td>\n",
       "      <td>326.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>1784</td>\n",
       "      <td>2018</td>\n",
       "      <td>43</td>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>GNB</td>\n",
       "      <td>QB</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>372</td>\n",
       "      <td>...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>333.3</td>\n",
       "      <td>358.3</td>\n",
       "      <td>331.666667</td>\n",
       "      <td>326.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>2387</td>\n",
       "      <td>2017</td>\n",
       "      <td>96</td>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>GNB</td>\n",
       "      <td>QB</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>154</td>\n",
       "      <td>...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.4</td>\n",
       "      <td>333.3</td>\n",
       "      <td>358.3</td>\n",
       "      <td>331.666667</td>\n",
       "      <td>326.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>2838</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>GNB</td>\n",
       "      <td>QB</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>401</td>\n",
       "      <td>...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.7</td>\n",
       "      <td>333.3</td>\n",
       "      <td>358.3</td>\n",
       "      <td>331.666667</td>\n",
       "      <td>326.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3414</th>\n",
       "      <td>3437</td>\n",
       "      <td>2015</td>\n",
       "      <td>53</td>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>GNB</td>\n",
       "      <td>QB</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>347</td>\n",
       "      <td>...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>333.3</td>\n",
       "      <td>358.3</td>\n",
       "      <td>331.666667</td>\n",
       "      <td>326.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912</th>\n",
       "      <td>3939</td>\n",
       "      <td>2014</td>\n",
       "      <td>13</td>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>GNB</td>\n",
       "      <td>QB</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>341</td>\n",
       "      <td>...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>333.3</td>\n",
       "      <td>358.3</td>\n",
       "      <td>331.666667</td>\n",
       "      <td>326.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4515</th>\n",
       "      <td>4547</td>\n",
       "      <td>2013</td>\n",
       "      <td>90</td>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>GNB</td>\n",
       "      <td>QB</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.8</td>\n",
       "      <td>333.3</td>\n",
       "      <td>358.3</td>\n",
       "      <td>331.666667</td>\n",
       "      <td>326.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>5000</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>GNB</td>\n",
       "      <td>QB</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>371</td>\n",
       "      <td>...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>333.3</td>\n",
       "      <td>358.3</td>\n",
       "      <td>331.666667</td>\n",
       "      <td>326.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Year  Rank         Player Team Position  Age  Games_G  \\\n",
       "17            17  2021    18  Aaron Rodgers  GNB       QB   38       16   \n",
       "603          606  2020     8  Aaron Rodgers  GNB       QB   37       16   \n",
       "1229        1235  2019    56  Aaron Rodgers  GNB       QB   36       16   \n",
       "1774        1784  2018    43  Aaron Rodgers  GNB       QB   35       16   \n",
       "2375        2387  2017    96  Aaron Rodgers  GNB       QB   34        7   \n",
       "2822        2838  2016     3  Aaron Rodgers  GNB       QB   33       16   \n",
       "3414        3437  2015    53  Aaron Rodgers  GNB       QB   32       16   \n",
       "3912        3939  2014    13  Aaron Rodgers  GNB       QB   31       16   \n",
       "4515        4547  2013    90  Aaron Rodgers  GNB       QB   30        9   \n",
       "4962        5000  2012    11  Aaron Rodgers  GNB       QB   29       16   \n",
       "\n",
       "      Games_GS  Passing_Cmp  ...  Combine_Year   Ft   In        Ht   ADP  \\\n",
       "17          16          366  ...        2005.0  6.0  2.0  6.166667  61.0   \n",
       "603         16          372  ...        2005.0  6.0  2.0  6.166667  96.0   \n",
       "1229        16          353  ...        2005.0  6.0  2.0  6.166667  58.0   \n",
       "1774        16          372  ...        2005.0  6.0  2.0  6.166667  31.0   \n",
       "2375         7          154  ...        2005.0  6.0  2.0  6.166667  25.0   \n",
       "2822        16          401  ...        2005.0  6.0  2.0  6.166667  40.0   \n",
       "3414        16          347  ...        2005.0  6.0  2.0  6.166667  27.0   \n",
       "3912        16          341  ...        2005.0  6.0  2.0  6.166667  23.0   \n",
       "4515         9          193  ...        2005.0  6.0  2.0  6.166667  32.0   \n",
       "4962        16          371  ...        2005.0  6.0  2.0  6.166667   3.0   \n",
       "\n",
       "      AvgMockDraftPosition  2Y_avg  3Y_avg      4Y_avg  5Y_avg  \n",
       "17                    59.0   333.3   358.3  331.666667   326.9  \n",
       "603                   94.3   333.3   358.3  331.666667   326.9  \n",
       "1229                  55.7   333.3   358.3  331.666667   326.9  \n",
       "1774                  31.4   333.3   358.3  331.666667   326.9  \n",
       "2375                  23.4   333.3   358.3  331.666667   326.9  \n",
       "2822                  38.7   333.3   358.3  331.666667   326.9  \n",
       "3414                  27.1   333.3   358.3  331.666667   326.9  \n",
       "3912                  22.2   333.3   358.3  331.666667   326.9  \n",
       "4515                  31.8   333.3   358.3  331.666667   326.9  \n",
       "4962                   3.4   333.3   358.3  331.666667   326.9  \n",
       "\n",
       "[10 rows x 76 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def three_year_avg(df, row):\n",
    "    year = row['Year']\n",
    "    min_year = year - 3\n",
    "    if min_year > 2012:\n",
    "        min_data = df['Year']\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "out = []\n",
    "year_names = []\n",
    "years = arod_example_lag_data['Year'].unique()\n",
    "#for year_delta in [2, 3, 4, 5]:\n",
    "for year in years\n",
    "    minyear = year - 3\n",
    "    lagging_data = arod_example_lag_data[arod_example_lag_data['Year'] > minyear]\n",
    "    lagging_data = lagging_data[['Player', 'Fantasy_PPR']]\n",
    "    grouped_data = lagging_data.groupby(['Player']).mean().reset_index()\n",
    "    year_name= str(year)+'Y_avg'\n",
    "    arod_example_lag_data[year_name] = grouped_data['Fantasy_PPR'][0]\n",
    "    #out.append(grouped_data)\n",
    "    #year_names.append(str(year)+'Y_avg')\n",
    "\n",
    "#out_df = pd.DataFrame(out)\n",
    "arod_example_lag_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    326.9\n",
       "Name: Fantasy_PPR, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data['Fantasy_PPR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Year', 'Rank', 'Player', 'Team', 'Position', 'Age',\n",
       "       'Games_G', 'Games_GS', 'Passing_Cmp', 'Passing_Att', 'Passing_Yds',\n",
       "       'Passing_TD', 'Passing_Int', 'Rushing_Att', 'Rushing_Yds',\n",
       "       'Rushing_Y/A_x', 'Rushing_TD', 'Receiving_Tgt', 'Receiving_Rec',\n",
       "       'Receiving_Yds', 'Receiving_Y/R', 'Receiving_TD', 'Fumbles_Fmb',\n",
       "       'Fumbles_FL', 'Scoring_TD', 'Scoring_2PM', 'Scoring_2PP',\n",
       "       'Fantasy_FantPt', 'Fantasy_PPR', 'Fantasy_DKPt', 'Fantasy_FDPt',\n",
       "       'Fantasy_VBD', 'Fantasy_PosRank', 'Fantasy_OvRank', 'Passing_TD%',\n",
       "       'Passing_Int%', 'Passing_1D', 'Passing_Lng', 'Passing_Y/A',\n",
       "       'Passing_AY/A', 'Passing_Y/C', 'Passing_Y/G', 'Passing_Rate',\n",
       "       'Passing_QBR', 'Passing_Sk', 'Passing_Sk%', 'Passing_NY/A',\n",
       "       'Passing_ANY/A', 'Rushing_1D', 'Rushing_Lng', 'Rushing_Y/A_y',\n",
       "       'Rushing_Y/G', 'Receiving_Ctch%', 'Receiving_Lng', 'Receiving_Y/Tgt',\n",
       "       'Receiving_R/G', 'Receiving_Y/G', 'School', 'Wt', '40yd', 'Vertical',\n",
       "       'Bench', 'BroadJump', '3Cone', 'Shuttle', 'Combine_Year', 'Ft', 'In',\n",
       "       'Ht', 'ADP', 'AvgMockDraftPosition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lagging_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
