{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in and preprocess Datasets (Fantasy, Combine, Advanced Statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fantasy Data (trailing 10 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Fantasy data from Pro Football Reference\n",
    "\n",
    "years_for_pfr_data = ['2021',\n",
    "                    '2020',\n",
    "                    '2019',\n",
    "                    '2018',\n",
    "                    '2017',\n",
    "                    '2016',\n",
    "                    '2015',\n",
    "                    '2014',\n",
    "                    '2013',\n",
    "                    '2012',\n",
    "                    ]\n",
    "\n",
    "fantasy_dfs = []\n",
    "for year in years_for_pfr_data: \n",
    "    link = \"https://www.pro-football-reference.com/years/\" + year + \"/fantasy.htm\" \n",
    "    df = pd.read_html(link)[0]\n",
    "    df['Year'] = year\n",
    "    fantasy_dfs.append(df)\n",
    "    \n",
    "fantasy_df = pd.concat(fantasy_dfs).reset_index(drop=True)\n",
    "\n",
    "# Flatten dataframe\n",
    "fantasy_df.columns = fantasy_df.columns.get_level_values(0) + '_' +  fantasy_df.columns.get_level_values(1)\n",
    "\n",
    "## Preprocess data\n",
    "# Rename Columns\n",
    "new_col_names = {'Unnamed: 0_level_0_Rk': 'Rank',\n",
    "        'Unnamed: 1_level_0_Player': 'Player',\n",
    "        'Unnamed: 2_level_0_Tm': 'Team',\n",
    "        'Unnamed: 3_level_0_FantPos': 'Position',\n",
    "        'Unnamed: 4_level_0_Age': 'Age',\n",
    "        'Year_': 'Year'}\n",
    "        \n",
    "fantasy_df.rename(columns=new_col_names, inplace=True)\n",
    "\n",
    "# Drop rows where column names are printed again (formatting issue w/ PFR website)\n",
    "fantasy_df = fantasy_df[~fantasy_df['Rank'].isin(['Rk'])]\n",
    "\n",
    "# Drop rows where Position is null (formatting issue w/ PFR website)\n",
    "fantasy_df = fantasy_df[fantasy_df['Position'].notna()]\n",
    "\n",
    "# Clean Player Name Column\n",
    "fantasy_df['Player'] = fantasy_df['Player'].str.strip('*+')\n",
    "\n",
    "# Fill NaN cells with 0\n",
    "fantasy_df = fantasy_df.fillna(0)\n",
    "\n",
    "# Rank Overall Fantasy Rank by Year (All values weren't filled in initally, must be added to dataset in place of zeros)\n",
    "# ...\n",
    "\n",
    "# Update Datatypes for columns\n",
    "convert_dtype_dict = {'Rank': int,\n",
    "                'Player': str,\n",
    "                'Team': str,\n",
    "                'Position': str,\n",
    "                'Age': int,\n",
    "                'Games_G': int,\n",
    "                'Games_GS': int,\n",
    "                'Passing_Cmp': int,\n",
    "                'Passing_Att': int,\n",
    "                'Passing_Yds': int,\n",
    "                'Passing_TD': int,\n",
    "                'Passing_Int': int,\n",
    "                'Rushing_Att': int,\n",
    "                'Rushing_Yds': int,\n",
    "                'Rushing_Y/A': float,\n",
    "                'Rushing_TD': int,\n",
    "                'Receiving_Tgt': int,\n",
    "                'Receiving_Rec': int,\n",
    "                'Receiving_Yds': int,\n",
    "                'Receiving_Y/R': float,\n",
    "                'Receiving_TD': int,\n",
    "                'Fumbles_Fmb': int,\n",
    "                'Fumbles_FL': int,\n",
    "                'Scoring_TD': int,\n",
    "                'Scoring_2PM': int,\n",
    "                'Scoring_2PP': int,\n",
    "                'Fantasy_FantPt': int,\n",
    "                'Fantasy_PPR': float,\n",
    "                'Fantasy_DKPt': float,\n",
    "                'Fantasy_FDPt': float,\n",
    "                'Fantasy_VBD': float,\n",
    "                'Fantasy_PosRank': int,\n",
    "                'Fantasy_OvRank': int,\n",
    "                'Year': str\n",
    "                }\n",
    " \n",
    "fantasy_df = fantasy_df.astype(convert_dtype_dict)\n",
    "\n",
    "# shift column 'Year' to first position\n",
    "first_column = fantasy_df.pop('Year')\n",
    "  \n",
    "# insert column at front of df\n",
    "fantasy_df.insert(0, 'Year', first_column)\n",
    "\n",
    "# Uncomment to Save dataset as flatfile (if desired)\n",
    "#fantasy_df.to_csv('data/pfr_10yr_data_2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Analytics from PFR (trailing 10 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Passing Data\n",
    "years_for_pfr_data = ['2021',\n",
    "                    '2020',\n",
    "                    '2019',\n",
    "                    '2018',\n",
    "                    '2017',\n",
    "                    '2016',\n",
    "                    '2015',\n",
    "                    '2014',\n",
    "                    '2013',\n",
    "                    '2012',\n",
    "                    ]\n",
    "\n",
    "passing_dfs = []\n",
    "for year in years_for_pfr_data: \n",
    "    link = \"https://www.pro-football-reference.com/years/\" + year + \"/passing.htm\" \n",
    "    df = pd.read_html(link)[0]\n",
    "    df['Year'] = year\n",
    "    passing_dfs.append(df)\n",
    "    \n",
    "passing_df = pd.concat(passing_dfs).reset_index(drop=True)\n",
    "\n",
    "# Rename Columns\n",
    "new_col_names = {'Rk': 'Rank',\n",
    "        'Att': 'Passing_Att',\n",
    "        'TD%': 'Passing_TD%',\n",
    "        'Int%': 'Passing_Int%',\n",
    "        '1D': 'Passing_1D',\n",
    "        'Lng': 'Passing_Lng',\n",
    "        'Y/A': 'Passing_Y/A',\n",
    "        'AY/A': 'Passing_AY/A',\n",
    "        'Y/C': 'Passing_Y/C',\n",
    "        'Y/G': 'Passing_Y/G',\n",
    "        'Rate': 'Passing_Rate',\n",
    "        'QBR': 'Passing_QBR',\n",
    "        'Sk': 'Passing_Sk',\n",
    "        'Sk%': 'Passing_Sk%',\n",
    "        'NY/A': 'Passing_NY/A',\n",
    "        'ANY/A': 'Passing_ANY/A'}\n",
    "        \n",
    "passing_df.rename(columns=new_col_names, inplace=True)\n",
    "\n",
    "# Drop rows where column names are printed again (formatting issue w/ PFR website)\n",
    "passing_df = passing_df[~passing_df['Rank'].isin(['Rk'])]\n",
    "\n",
    "# Clean Player Name Column\n",
    "passing_df['Player'] = passing_df['Player'].str.strip('*+')\n",
    "\n",
    "# Update Datatypes for columns\n",
    "convert_dtype_dict = {'Player': str,\n",
    "                'Passing_Att': int,\n",
    "                'Passing_TD%': float,\n",
    "                'Passing_Int%': float,\n",
    "                'Passing_1D': int,\n",
    "                'Passing_Lng': int,\n",
    "                'Passing_Y/A': float,\n",
    "                'Passing_AY/A': float,\n",
    "                'Passing_Y/C': float,\n",
    "                'Passing_Y/G': float,\n",
    "                'Passing_Rate': float,\n",
    "                'Passing_QBR': float,\n",
    "                'Passing_Sk': str,\n",
    "                'Passing_Sk%': float,\n",
    "                'Passing_NY/A': float,\n",
    "                'Passing_ANY/A': float\n",
    "                }\n",
    "passing_df = passing_df.astype(convert_dtype_dict)\n",
    "\n",
    "# Downselect rows to players that threw 20 or more passes\n",
    "passing_df = passing_df[passing_df['Passing_Att'] >= 20]\n",
    "\n",
    "# Downselect columns\n",
    "passing_df = passing_df[['Player','Passing_TD%','Passing_Int%','Passing_1D','Passing_Lng','Passing_Y/A','Passing_AY/A','Passing_Y/C','Passing_Y/G','Passing_Rate','Passing_QBR','Passing_Sk','Passing_Sk%','Passing_NY/A','Passing_ANY/A','Year']]\n",
    "\n",
    "# Uncomment to Save dataset as flatfile (if desired)\n",
    "passing_df.to_csv('data/pfr_10yr_passing_data_2022.csv')\n",
    "\n",
    "\n",
    "## Rushing Data\n",
    "rushing_dfs = []\n",
    "for year in years_for_pfr_data: \n",
    "    link = \"https://www.pro-football-reference.com/years/\" + year + \"/rushing.htm\" \n",
    "    df = pd.read_html(link)[0]\n",
    "    df['Year'] = year\n",
    "    rushing_dfs.append(df)\n",
    "    \n",
    "rushing_df = pd.concat(rushing_dfs).reset_index(drop=True)\n",
    "\n",
    "# Flatten dataframe\n",
    "rushing_df.columns = rushing_df.columns.get_level_values(0) + '_' +  rushing_df.columns.get_level_values(1)\n",
    "\n",
    "# Rename Columns\n",
    "new_col_names = {'Unnamed: 0_level_0_Rk': 'Rank',\n",
    "        'Unnamed: 1_level_0_Player': 'Player',\n",
    "        'Unnamed: 2_level_0_Tm': 'Team',\n",
    "        'Unnamed: 3_level_0_Age': 'Age',\n",
    "        'Unnamed: 4_level_0_Pos': 'Position',\n",
    "        'Unnamed: 14_level_0_Fmb': 'Rushing_Fumbles',\n",
    "        'Year_': 'Year'}\n",
    "        \n",
    "rushing_df.rename(columns=new_col_names, inplace=True)\n",
    "\n",
    "# Drop rows where column names are printed again (formatting issue w/ PFR website)\n",
    "rushing_df = rushing_df[~rushing_df['Rank'].isin(['Rk'])]\n",
    "\n",
    "# Clean Player Name Column\n",
    "rushing_df['Player'] = rushing_df['Player'].str.strip('*+')\n",
    "\n",
    "# Update Datatypes for columns\n",
    "convert_dtype_dict = {'Player': str,\n",
    "                'Rushing_1D': int,\n",
    "                'Rushing_Lng': int,\n",
    "                'Rushing_Y/A': float,\n",
    "                'Rushing_Y/G': float,\n",
    "                'Rushing_Fumbles': int,\n",
    "                'Year': str\n",
    "                }\n",
    "rushing_df = rushing_df.astype(convert_dtype_dict)\n",
    "\n",
    "# Downselect columns\n",
    "rushing_df = rushing_df[['Player','Rushing_1D','Rushing_Lng','Rushing_Y/A','Rushing_Y/G','Rushing_Fumbles','Year']]\n",
    "\n",
    "# Uncomment to Save dataset as flatfile (if desired)\n",
    "rushing_df.to_csv('data/pfr_10yr_rushing_data_2022.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Receiving Data\n",
    "receiving_dfs = []\n",
    "for year in years_for_pfr_data: \n",
    "    link = \"https://www.pro-football-reference.com/years/\" + year + \"/receiving.htm\" \n",
    "    df = pd.read_html(link)[0]\n",
    "    df['Year'] = year\n",
    "    receiving_dfs.append(df)\n",
    "    \n",
    "receiving_df = pd.concat(receiving_dfs).reset_index(drop=True)\n",
    "\n",
    "# Rename Columns\n",
    "new_col_names = {'Rk': 'Rank',\n",
    "        'Ctch%': 'Receiving_Ctch%',\n",
    "        'Lng': 'Receiving_Lng',\n",
    "        'Y/Tgt': 'Receiving_Y/Tgt',\n",
    "        'R/G': 'Receiving_R/G',\n",
    "        'Y/G': 'Receiving_Y/G',\n",
    "        'Year_': 'Year'}\n",
    "        \n",
    "receiving_df.rename(columns=new_col_names, inplace=True)\n",
    "\n",
    "# Drop rows where column names are printed again (formatting issue w/ PFR website)\n",
    "receiving_df = receiving_df[~receiving_df['Rank'].isin(['Rk'])]\n",
    "\n",
    "# Clean Player Name Column\n",
    "receiving_df['Player'] = receiving_df['Player'].str.strip('*+')\n",
    "# Clean Player Name Column\n",
    "receiving_df['Receiving_Ctch%'] = receiving_df['Receiving_Ctch%'].str.strip('%')\n",
    "\n",
    "# Update Datatypes for columns\n",
    "convert_dtype_dict = {'Player': str,\n",
    "                'Receiving_Ctch%': float,\n",
    "                'Receiving_Lng': int,\n",
    "                'Receiving_Y/Tgt': float,\n",
    "                'Receiving_R/G': float,\n",
    "                'Receiving_Y/G': float,\n",
    "                'Year': str\n",
    "                }\n",
    "receiving_df = receiving_df.astype(convert_dtype_dict)\n",
    "\n",
    "# Downselect columns\n",
    "#receiving_df = receiving_df[['Player','Receiving_Ctch%','Receiving_Lng','Receiving_Y/Tgt','Receiving_R/G','Receiving_Y/G','Year']]\n",
    "receiving_df = receiving_df[['Player','Receiving_Ctch%','Receiving_Lng','Receiving_Y/Tgt','Receiving_R/G','Year']]\n",
    "\n",
    "# Uncomment to Save dataset as flatfile (if desired)\n",
    "receiving_df.to_csv('data/pfr_10yr_receiving_data_2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Analytics from PFR (trailing 10 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add at later date...\n",
    "#https://www.pro-football-reference.com/years/2021/passing_advanced.htm\n",
    "#https://www.pro-football-reference.com/years/2021/rushing_advanced.htm\n",
    "#https://www.pro-football-reference.com/years/2021/receiving_advanced.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fantasy Draft ADP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import flat files of fantasy mock draft adp data from Fantasy Football Calculator\n",
    "years_for_adp_data = ['2022',\n",
    "                    '2021',\n",
    "                    '2020',\n",
    "                    '2019',\n",
    "                    '2018',\n",
    "                    '2017',\n",
    "                    '2016',\n",
    "                    '2015',\n",
    "                    '2014',\n",
    "                    '2013',\n",
    "                    '2012'\n",
    "                    ]\n",
    "\n",
    "fantasy_draft_adp_dfs = []\n",
    "for year in years_for_adp_data: \n",
    "    filename = \"data/fantasy_draft_adp/draft_adp_\" + year + \".csv\" \n",
    "    df = pd.read_csv(filename)\n",
    "    df['Year'] = year\n",
    "    fantasy_draft_adp_dfs.append(df)\n",
    "    \n",
    "fantasy_draft_adp_df = pd.concat(fantasy_draft_adp_dfs).reset_index(drop=True)\n",
    "\n",
    "fantasy_draft_adp_df.rename(columns={'#':'ADP', 'Name':'Player', 'Overall':'AvgMockDraftPosition', 'Pos': 'Position'}, inplace=True)\n",
    "\n",
    "fantasy_draft_adp_df\n",
    "fantasy_draft_adp_df_reduced = fantasy_draft_adp_df[['ADP','Player','AvgMockDraftPosition','Year','Position']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NFL Pre-Draft Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NFL Combine Data from Pro Football Reference\n",
    "\n",
    "years_for_pfr_data = ['2022',\n",
    "                    '2021',\n",
    "                    '2020',\n",
    "                    '2019',\n",
    "                    '2018',\n",
    "                    '2017',\n",
    "                    '2016',\n",
    "                    '2015',\n",
    "                    '2014',\n",
    "                    '2013',\n",
    "                    '2012',\n",
    "                    '2011',\n",
    "                    '2010',\n",
    "                    '2009',\n",
    "                    '2008',\n",
    "                    '2007',\n",
    "                    '2006',\n",
    "                    '2005',\n",
    "                    '2004',\n",
    "                    '2003',\n",
    "                    '2002',\n",
    "                    '2001',\n",
    "                    '2000',\n",
    "                    ]\n",
    "\n",
    "combine_dfs = []\n",
    "for year in years_for_pfr_data: \n",
    "    link = \"https://www.pro-football-reference.com/draft/\" + year + \"-combine.htm\" \n",
    "    df = pd.read_html(link)[0]\n",
    "    df['Combine_Year'] = year\n",
    "    combine_dfs.append(df)\n",
    "    \n",
    "combine_df = pd.concat(combine_dfs).reset_index(drop=True)\n",
    "\n",
    "## Preprocess Data\n",
    "\n",
    "# Drop rows where column names are printed again (formatting issue w/ PFR website)\n",
    "combine_df = combine_df[~combine_df['Player'].isin(['Player'])]\n",
    "\n",
    "# Drop Unnecessary columns\n",
    "combine_df = combine_df.drop(['College','Drafted (tm/rnd/yr)'], axis=1)\n",
    "\n",
    "# Fill NaN cells with 0\n",
    "combine_df = combine_df.fillna(0)\n",
    "# Fill NaN cells with median value of column\n",
    "#combine_df.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "\n",
    "# Update height column to usable number value\n",
    "ht_df = combine_df[\"Ht\"].str.split(\"-\", n = 1, expand = True)\n",
    "combine_df[\"Ft\"] = ht_df[0]\n",
    "combine_df = combine_df.fillna(0)\n",
    "combine_df[\"Ft\"] = combine_df[\"Ft\"].astype('int')\n",
    "combine_df[\"In\"] = ht_df[1]\n",
    "combine_df = combine_df.fillna(0)\n",
    "combine_df[\"In\"] = combine_df[\"In\"].astype('int')\n",
    "combine_df.drop(columns =[\"Ht\"], inplace = True)\n",
    "combine_df[\"Ht\"] = combine_df['Ft'] + combine_df['In']/12\n",
    "\n",
    "\n",
    "# Update Datatypes for columns\n",
    "convert_dtype_dict = {'Player': str,\n",
    "                'Pos':str,\n",
    "                'School': str,\n",
    "                'Ht': float,\n",
    "                'Wt': int,\n",
    "                '40yd': float,\n",
    "                'Vertical': float,\n",
    "                'Bench': int,\n",
    "                'Broad Jump': int,\n",
    "                '3Cone': float,\n",
    "                'Shuttle': float,\n",
    "                'Combine_Year': str,\n",
    "                }\n",
    "combine_df = combine_df.astype(convert_dtype_dict)\n",
    "\n",
    "combine_df.rename(columns={'Broad Jump': 'BroadJump', 'Pos':'Position'}, inplace=True)\n",
    "\n",
    "\n",
    "# Uncomment to Save combine dataset as flatfile (if desired)\n",
    "combine_df.to_csv('data/pfr_combine_data_2000_thru_2022.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join in other data specific to players (combine results, standard/advanced analytics, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Fantasy points data with passing data\n",
    "final_df = fantasy_df.merge(passing_df, how='left', on=['Player','Year'])\n",
    "\n",
    "# Merge DF with rushing data\n",
    "final_df = final_df.merge(rushing_df, how='left', on=['Player','Year'])\n",
    "\n",
    "# Merge DF with receiving data\n",
    "final_df = final_df.merge(receiving_df, how='left', on=['Player','Year'])\n",
    "\n",
    "# Merge in Fantasy Draft ADP\n",
    "final_df = final_df.merge(fantasy_draft_adp_df_reduced, how='outer', on=['Player','Year'])\n",
    "\n",
    "# Merge Fantasy points data with combine data (fix later, pulling in name multiples)\n",
    "final_df = final_df.merge(combine_df, how='left', on=['Player','Position'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Second Josh Allen's combined data (Kentucky Josh)\n",
    "- lol\n",
    "- and also Mike Williams, Adrian Peterson, Alex Smith, and David Johnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are duplicates where players that share names with other players\n",
    "val_cnt_rows = final_df.Player.value_counts()\n",
    "val_cnt_rows.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Josh Allen for this study\n",
    "ja = final_df[((final_df['Player'] == 'Josh Allen') & (final_df['Combine_Year'] == \"2019\"))].index\n",
    "final_df = final_df.drop(ja)\n",
    "\n",
    "# One Mike Williams for this study\n",
    "mw = final_df[((final_df['Player'] == 'Mike Williams') & ((final_df['Combine_Year'] == \"2005\") | (final_df['Combine_Year'] == \"2010\")))].index\n",
    "final_df = final_df.drop(mw)\n",
    "\n",
    "# One Adrian Peterson for this study\n",
    "ap = final_df[((final_df['Player'] == 'Adrian Peterson') & (final_df['Combine_Year'] == \"2002\"))].index\n",
    "final_df = final_df.drop(ap)\n",
    "\n",
    "# One Alex Smith for this study\n",
    "als = final_df[((final_df['Player'] == 'Alex Smith') & (final_df['Position']==\"TE\"))].index\n",
    "final_df = final_df.drop(als)\n",
    "\n",
    "# One David Johnson for this study\n",
    "dj = final_df[((final_df['Player'] == 'David Johnson') & (final_df['Combine_Year'].isna()))].index\n",
    "final_df = final_df.drop(dj)\n",
    "dj_pt2 = final_df[((final_df['Player'] == 'David Johnson') & (final_df['Year'] == '2015') & ((final_df['Rushing_1D']  < 36) | (final_df['Receiving_Lng'] < 55)))].index\n",
    "final_df = final_df.drop(dj_pt2)\n",
    "dj_pt3 = final_df[((final_df['Player'] == 'David Johnson') & (final_df['Year'] == '2016') & (final_df['Receiving_Lng'] < 58))].index\n",
    "final_df = final_df.drop(dj_pt3)\n",
    "\n",
    "final_df = final_df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add additional custom parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add as necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save final_df as master dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated master dataframe\n",
    "final_df.to_csv('data/master_df_w_2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number 1 ranked players from each fantasy season\n",
    "fantasy_df[fantasy_df['Fantasy_OvRank']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One players Fantasy Prodution during career\n",
    "fantasy_df[fantasy_df['Player']==\"Todd Gurley\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions located in this cell\n",
    "# Do one for pulling pfr data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Line plot of Age vs Fantasy PPR points (line by position)\n",
    "# Groupby on Data\n",
    "top_20_pos_rk_players = fantasy_df[fantasy_df['Fantasy_PosRank'] <= 20]\n",
    "age_pos_avg_ppr_gb = top_20_pos_rk_players.groupby(['Age','Position']).mean('Fantasy_PPR').reset_index()\n",
    "\n",
    "# Seaborn\n",
    "\n",
    "#age_pos_ppr_fig = sns.lineplot(data=age_pos_avg_ppr_gb, x='Age', y='Fantasy_PPR', hue='Position')\n",
    "#age_pos_ppr_fig.set_title('Average Fantasy Points (PPR) by Age and Position')\n",
    "#age_pos_ppr_fig.set_xlabel('Age')\n",
    "#age_pos_ppr_fig.set_ylabel('Fantasy Points')\n",
    "\n",
    "# Plotly\n",
    "age_pos_ppr_fig_px = px.line(age_pos_avg_ppr_gb, x=\"Age\", y=\"Fantasy_PPR\", color='Position', title='Average Fantasy Points (PPR) by Age and Position')\n",
    "plot_filename='plots/avg_points_by_age_position.html'\n",
    "age_pos_ppr_fig_px.write_html(plot_filename)\n",
    "age_pos_ppr_fig_px.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Line plot of count on top 20 players at each position by Age (line by position)\n",
    "# Groupby on Data\n",
    "top_20_pos_rk_players = fantasy_df[fantasy_df['Fantasy_PosRank'] <= 20]\n",
    "age_pos_count_gb = top_20_pos_rk_players.groupby(['Age','Position']).count().reset_index()\n",
    "\n",
    "# Plotly\n",
    "posrnk_age_count_plot_px = px.line(age_pos_count_gb, x=\"Age\", y=\"Rank\", color='Position', title='Number of Top 20 Position Rankings by Age and Position')\n",
    "posrnk_age_count_plot_px.update_layout(\n",
    "                   xaxis_title='Age',\n",
    "                   yaxis_title='Count of Top 20 Players')\n",
    "plot_filename='plots/top20_player_count_by_age_position.html'\n",
    "posrnk_age_count_plot_px.write_html(plot_filename)\n",
    "posrnk_age_count_plot_px.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scatter plot of Position Rank vs Fantasy PPR points (Color by Position)\n",
    "\n",
    "# Seaborn\n",
    "#posrnk_ppr_plot_sns = sns.scatterplot(data=final_df, x='Fantasy_PosRank', y='Fantasy_PPR', hue='Position')\n",
    "#posrnk_ppr_plot_sns.set_title('Average Fantasy Points (PPR) by Position')\n",
    "#posrnk_ppr_plot_sns.set_xlabel('Position Rank')\n",
    "#posrnk_ppr_plot_sns.set_ylabel('Fantasy Points')\n",
    "\n",
    "# Plotly\n",
    "posrnk_ppr_plot_px = px.scatter(fantasy_df, x=\"Fantasy_PosRank\", y=\"Fantasy_PPR\", color='Position', hover_data=['Player', 'Year'], title='Fantasy Points (PPR) by Position and Rank')\n",
    "plot_filename='plots/points_by_position.html'\n",
    "posrnk_ppr_plot_px.write_html(plot_filename)\n",
    "posrnk_ppr_plot_px.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of position vs Fantasy points\n",
    "# Seaborn\n",
    "#box_pos_ppr_sns = sns.boxplot(data=final_df, x='Position', y='Fantasy_PPR')\n",
    "\n",
    "# Plotly\n",
    "box_pos_ppr_px = px.box(fantasy_df, x=\"Position\", y=\"Fantasy_PPR\", hover_data=['Player', 'Year'], title='Fantasy Points by Position')\n",
    "plot_filename='plots/boxplot_points_by_position.html'\n",
    "box_pos_ppr_px.write_html(plot_filename)\n",
    "box_pos_ppr_px.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rbs_speed = final_df[(final_df['Position'] == 'RB') & (final_df['40yd'] > 0)]\n",
    "#rb_speed_ppr_px = px.scatter(rbs_speed, x='40yd', y='Fantasy_PPR', hover_data=['Player'])\n",
    "#rb_speed_ppr_px.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "qbs_speed = final_df[(final_df['Position'] == 'QB') & (final_df['40yd'] > 0)]\n",
    "rbs_speed = final_df[(final_df['Position'] == 'RB') & (final_df['40yd'] > 0)]\n",
    "wrs_speed = final_df[(final_df['Position'] == 'WR') & (final_df['40yd'] > 0)]\n",
    "tes_speed = final_df[(final_df['Position'] == 'TE') & (final_df['40yd'] > 0)]\n",
    "\n",
    "speed_and_pos_vs_points = make_subplots(rows=2, cols=2, subplot_titles=('Quarterback', 'Running Back', 'Wide Receiver', 'Tight End'))\n",
    "\n",
    "speed_and_pos_vs_points.add_trace(\n",
    "    go.Scatter(\n",
    "        x=qbs_speed['40yd'],\n",
    "        y=qbs_speed['Fantasy_PPR'],\n",
    "        mode='markers'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "speed_and_pos_vs_points.add_trace(\n",
    "    go.Scatter(\n",
    "        x=rbs_speed['40yd'],\n",
    "        y=rbs_speed['Fantasy_PPR'],\n",
    "        mode='markers'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "speed_and_pos_vs_points.add_trace(\n",
    "    go.Scatter(\n",
    "        x=wrs_speed['40yd'],\n",
    "        y=wrs_speed['Fantasy_PPR'],\n",
    "        mode='markers'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "speed_and_pos_vs_points.add_trace(\n",
    "    go.Scatter(\n",
    "        x=tes_speed['40yd'],\n",
    "        y=tes_speed['Fantasy_PPR'],\n",
    "        mode='markers'\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Update xaxis properties\n",
    "speed_and_pos_vs_points.update_xaxes(title_text=\"40-yd Dash time (secs)\", range=[4, 6], row=1, col=1)\n",
    "speed_and_pos_vs_points.update_xaxes(title_text=\"40-yd Dash time (secs)\", range=[4, 6], row=1, col=2)\n",
    "speed_and_pos_vs_points.update_xaxes(title_text=\"40-yd Dash time (secs)\", range=[4, 6], row=2, col=1)\n",
    "speed_and_pos_vs_points.update_xaxes(title_text=\"40-yd Dash time (secs)\", range=[4, 6], row=2, col=2)\n",
    "\n",
    "# Update yaxis properties\n",
    "speed_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=[0, 500], row=1, col=1)\n",
    "speed_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=[0, 500], row=1, col=2)\n",
    "speed_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=[0, 500], row=2, col=1)\n",
    "speed_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=[0, 500], row=2, col=2)\n",
    "\n",
    "speed_and_pos_vs_points.update_layout(title_text=\"Fantasy Points (PPR) vs 40-Time by Position\", height=600, showlegend=False)\n",
    "\n",
    "plot_filename='plots/speed_vs_points_and_position.html'\n",
    "speed_and_pos_vs_points.write_html(plot_filename)\n",
    "speed_and_pos_vs_points.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qbs_vert = final_df[(final_df['Position'] == 'QB') & (final_df['Vertical'] > 0)]\n",
    "rbs_vert = final_df[(final_df['Position'] == 'RB') & (final_df['Vertical'] > 0)]\n",
    "wrs_vert = final_df[(final_df['Position'] == 'WR') & (final_df['Vertical'] > 0)]\n",
    "tes_vert = final_df[(final_df['Position'] == 'TE') & (final_df['Vertical'] > 0)]\n",
    "\n",
    "vert_and_pos_vs_points = make_subplots(rows=2, cols=2, subplot_titles=('Quarterback', 'Running Back', 'Wide Receiver', 'Tight End'))\n",
    "\n",
    "vert_and_pos_vs_points.add_trace(\n",
    "    go.Scatter(\n",
    "        x=qbs_vert['Vertical'],\n",
    "        y=qbs_vert['Fantasy_PPR'],\n",
    "        mode='markers'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "vert_and_pos_vs_points.add_trace(\n",
    "    go.Scatter(\n",
    "        x=rbs_vert['Vertical'],\n",
    "        y=rbs_vert['Fantasy_PPR'],\n",
    "        mode='markers'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "vert_and_pos_vs_points.add_trace(\n",
    "    go.Scatter(\n",
    "        x=wrs_vert['Vertical'],\n",
    "        y=wrs_vert['Fantasy_PPR'],\n",
    "        mode='markers'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "vert_and_pos_vs_points.add_trace(\n",
    "    go.Scatter(\n",
    "        x=tes_vert['Vertical'],\n",
    "        y=tes_vert['Fantasy_PPR'],\n",
    "        mode='markers'\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Update xaxis properties\n",
    "vert_and_pos_vs_points.update_xaxes(title_text=\"Vertical Jump (inches)\", range=[10, 50], row=1, col=1)\n",
    "vert_and_pos_vs_points.update_xaxes(title_text=\"Vertical Jump (inches)\", range=[10, 50], row=1, col=2)\n",
    "vert_and_pos_vs_points.update_xaxes(title_text=\"Vertical Jump (inches)\", range=[10, 50], row=2, col=1)\n",
    "vert_and_pos_vs_points.update_xaxes(title_text=\"Vertical Jump (inches)\", range=[10, 50], row=2, col=2)\n",
    "\n",
    "# Update yaxis properties\n",
    "vert_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=[0, 500], row=1, col=1)\n",
    "vert_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=[0, 500], row=1, col=2)\n",
    "vert_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=[0, 500], row=2, col=1)\n",
    "vert_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=[0, 500], row=2, col=2)\n",
    "\n",
    "vert_and_pos_vs_points.update_layout(title_text=\"Fantasy Points (PPR) vs Vertical Jump by Position\", height=600, showlegend=False)\n",
    "\n",
    "plot_filename='plots/vert_vs_points_and_position.html'\n",
    "vert_and_pos_vs_points.write_html(plot_filename)\n",
    "vert_and_pos_vs_points.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pts_vs_combine_scatterplots(df, subplot_config, yaxis_range=[0,500]):\n",
    "    for plot in subplot_config['plots']:\n",
    "        print(\"Using \"+plot['args']['measurement']+\" for plot...\")\n",
    "        measure = plot['args']['measurement']\n",
    "        unit = plot['args']['units']\n",
    "        xrange = plot['args']['xrange']\n",
    "\n",
    "        qbs = df[(df['Position'] == 'QB') & (df[measure] > 0)]\n",
    "        rbs = df[(df['Position'] == 'RB') & (df[measure] > 0)]\n",
    "        wrs = df[(df['Position'] == 'WR') & (df[measure] > 0)]\n",
    "        tes = df[(df['Position'] == 'TE') & (df[measure] > 0)]\n",
    "\n",
    "        meas_and_pos_vs_points = make_subplots(rows=2, cols=2, subplot_titles=('Quarterback', 'Running Back', 'Wide Receiver', 'Tight End'))\n",
    "\n",
    "        meas_and_pos_vs_points.add_trace(\n",
    "            go.Scatter(\n",
    "                x=qbs[measure],\n",
    "                y=qbs['Fantasy_PPR'],\n",
    "                mode='markers'\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "        meas_and_pos_vs_points.add_trace(\n",
    "            go.Scatter(\n",
    "                x=rbs[measure],\n",
    "                y=rbs['Fantasy_PPR'],\n",
    "                mode='markers'\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "\n",
    "        meas_and_pos_vs_points.add_trace(\n",
    "            go.Scatter(\n",
    "                x=wrs[measure],\n",
    "                y=wrs['Fantasy_PPR'],\n",
    "                mode='markers'\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "\n",
    "        meas_and_pos_vs_points.add_trace(\n",
    "            go.Scatter(\n",
    "                x=tes[measure],\n",
    "                y=tes['Fantasy_PPR'],\n",
    "                mode='markers'\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "\n",
    "        # Update xaxis properties\n",
    "        x_title = str(measure)+' ('+str(unit)+')'\n",
    "        meas_and_pos_vs_points.update_xaxes(title_text=x_title, range=xrange, row=1, col=1)\n",
    "        meas_and_pos_vs_points.update_xaxes(title_text=x_title, range=xrange, row=1, col=2)\n",
    "        meas_and_pos_vs_points.update_xaxes(title_text=x_title, range=xrange, row=2, col=1)\n",
    "        meas_and_pos_vs_points.update_xaxes(title_text=x_title, range=xrange, row=2, col=2)\n",
    "\n",
    "        # Update yaxis properties\n",
    "        meas_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=yaxis_range, row=1, col=1)\n",
    "        meas_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=yaxis_range, row=1, col=2)\n",
    "        meas_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=yaxis_range, row=2, col=1)\n",
    "        meas_and_pos_vs_points.update_yaxes(title_text=\"Fantasy Points (PPR)\", range=yaxis_range, row=2, col=2)\n",
    "\n",
    "        meas_and_pos_vs_points.update_layout(title_text=\"Fantasy Points (PPR) vs \"+str(measure)+\" by Position\", height=600, showlegend=False)\n",
    "\n",
    "        plot_filename='plots/'+str(measure)+'_vs_points_and_position.html'\n",
    "        meas_and_pos_vs_points.write_html(plot_filename)\n",
    "        print(\"Plot saved\")\n",
    "    print('')\n",
    "    print('Plots complete!')\n",
    "\n",
    "\n",
    "subplot_config = \\\n",
    "{\n",
    "    \"plots\":[\n",
    "        {\n",
    "            \"args\": {\n",
    "                \"measurement\":\"40yd\",\n",
    "                \"units\": 'secs',\n",
    "                \"xrange\": [4,6]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"args\": {\n",
    "                \"measurement\": \"Vertical\",\n",
    "                \"units\": 'inches',\n",
    "                \"xrange\": [20,50]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"args\": {\n",
    "                \"measurement\": \"Bench\",\n",
    "                \"units\": 'reps',\n",
    "                \"xrange\":[0,50]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"args\": {\n",
    "                \"measurement\": \"BroadJump\",\n",
    "                \"units\": 'inches',\n",
    "                \"xrange\": [80,150]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"args\": {\n",
    "                \"measurement\": \"3Cone\",\n",
    "                \"units\": 'secs',\n",
    "                \"xrange\": [6,9]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"args\": {\n",
    "                \"measurement\": \"Shuttle\",\n",
    "                \"units\": 'secs',\n",
    "                \"xrange\": [3.5,5.5]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "pts_vs_combine_scatterplots(final_df, subplot_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Dataset\n",
    "df = pd.read_csv('data/master_df.csv')\n",
    "\n",
    "# Separate Datasets by Position\n",
    "qbs = df[df['Position'] == 'QB']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = StandardScaler()\n",
    "#qb_reduced_df = qbs[['Age','Passing_TD%','Passing_Int%','Passing_1D','Passing_Lng','Passing_Y/A','Passing_AY/A','Passing_Y/C','Passing_Sk','Passing_Sk%','Passing_NY/A','Passing_ANY/A','Rushing_1D','Rushing_Lng','Rushing_Y/A_y','Fantasy_PPR']]\n",
    "#qb_reduced_df = qbs[['Age','Passing_TD%','Passing_Int%','Passing_Lng','Passing_Y/A','Passing_AY/A','Passing_Y/C','Passing_Sk','Passing_Sk%','Passing_NY/A','Passing_ANY/A','Rushing_Lng','Rushing_Y/A_y','Fantasy_PPR']]\n",
    "qb_reduced_df = qbs[['Age','Passing_TD%','Passing_Int%','Passing_Lng','Passing_Y/A','Passing_AY/A','Passing_Y/C','Passing_Sk%','Passing_NY/A','Passing_ANY/A','Rushing_Lng','Rushing_Y/A_y','Fantasy_PPR']]\n",
    "#qb_reduced_df = qb_reduced_df.dropna()\n",
    "qb_reduced_df.replace(0, np.nan, inplace=True)\n",
    "qb_reduced_df = qb_reduced_df.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "model.fit(qb_reduced_df)\n",
    "\n",
    "#qb_plt = sns.pairplot(qb_reduced_df)\n",
    "#plt.savefig('plots/qb_pairplot.png')\n",
    "qb_reduced_df.to_csv('data/qb_std_stats_no_1ds_or_sks.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Dataset\n",
    "df = pd.read_csv('data/master_df.csv')\n",
    "rbs = df[df['Position'] == 'RB']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = StandardScaler()\n",
    "#rb_reduced_df = rbs[['Age','Rushing_1D','Rushing_Lng','Rushing_Y/A_y','Receiving_Ctch%','Receiving_Lng','Receiving_Y/Tgt','Fantasy_PPR']]\n",
    "rb_reduced_df = rbs[['Age','Rushing_Fumbles','Rushing_Lng','Rushing_Y/A_y','Receiving_Ctch%','Receiving_Lng','Receiving_Y/Tgt','Fantasy_PPR']]\n",
    "#rb_reduced_df = rb_reduced_df.dropna()\n",
    "rb_reduced_df.replace(0, np.nan, inplace=True)\n",
    "rb_reduced_df = rb_reduced_df.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "model.fit(rb_reduced_df)\n",
    "rb_reduced_df.to_csv('data/rb_std_stats_no_1ds.csv')\n",
    "#rb_plt = sns.pairplot(rb_reduced_df)\n",
    "#plt.savefig('plots/rb_pairplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Dataset\n",
    "df = pd.read_csv('data/master_df.csv')\n",
    "\n",
    "wrs = df[df['Position'] == 'WR']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = StandardScaler()\n",
    "wr_reduced_df = wrs[['Age','Receiving_Ctch%','Receiving_Lng','Receiving_Y/Tgt','Fantasy_PPR']]\n",
    "#wr_reduced_df = wr_reduced_df.dropna()\n",
    "wr_reduced_df.replace(0, np.nan, inplace=True)\n",
    "wr_reduced_df = wr_reduced_df.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "model.fit(wr_reduced_df)\n",
    "\n",
    "#wr_plt = sns.pairplot(wr_reduced_df)\n",
    "#plt.savefig('plots/wr_pairplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Dataset\n",
    "df = pd.read_csv('data/master_df.csv')\n",
    "\n",
    "tes = df[df['Position'] == 'TE']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = StandardScaler()\n",
    "te_reduced_df = tes[['Age','Receiving_Ctch%','Receiving_Lng','Receiving_Y/Tgt','Fantasy_PPR']]\n",
    "#te_reduced_df = te_reduced_df.dropna()\n",
    "te_reduced_df.replace(0, np.nan, inplace=True)\n",
    "te_reduced_df = te_reduced_df.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "model.fit(te_reduced_df)\n",
    "\n",
    "#te_plt = sns.pairplot(te_reduced_df)\n",
    "#plt.savefig('plots/te_pairplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Dataset\n",
    "df = pd.read_csv('data/master_df.csv')\n",
    "\n",
    "# Separate Datasets by Position\n",
    "qbs = df[df['Position'] == 'QB']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = StandardScaler()\n",
    "qb_combine_df = qbs[['Ht','Wt','40yd','Vertical','Bench','BroadJump','3Cone','Shuttle','Combine_Year','Fantasy_PPR']]\n",
    "#qb_combine_df = qb_combine_df.dropna()\n",
    "qb_combine_df.replace(0, np.nan, inplace=True)\n",
    "qb_combine_df = qb_combine_df.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "model.fit(qb_combine_df)\n",
    "\n",
    "#qb_combine_plt = sns.pairplot(qb_combine_df)\n",
    "#plt.savefig('plots/qb_combine_pairplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Dataset\n",
    "df = pd.read_csv('data/master_df.csv')\n",
    "\n",
    "# Separate Datasets by Position\n",
    "rbs = df[df['Position'] == 'RB']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = StandardScaler()\n",
    "rb_combine_df = rbs[['Ht','Wt','40yd','Vertical','Bench','BroadJump','3Cone','Shuttle','Combine_Year','Fantasy_PPR']]\n",
    "#rb_combine_df = rb_combine_df.dropna()\n",
    "rb_combine_df.replace(0, np.nan, inplace=True)\n",
    "rb_combine_df = rb_combine_df.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "model.fit(rb_combine_df)\n",
    "\n",
    "rb_combine_plt = sns.pairplot(rb_combine_df)\n",
    "plt.savefig('plots/rb_combine_pairplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Dataset\n",
    "df = pd.read_csv('data/master_df.csv')\n",
    "\n",
    "# Separate Datasets by Position\n",
    "wrs = df[df['Position'] == 'WR']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = StandardScaler()\n",
    "wr_combine_df = wrs[['Ht','Wt','40yd','Vertical','Bench','BroadJump','3Cone','Shuttle','Combine_Year','Fantasy_PPR']]\n",
    "#wr_combine_df = wr_combine_df.dropna()\n",
    "wr_combine_df.replace(0, np.nan, inplace=True)\n",
    "wr_combine_df = wr_combine_df.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "model.fit(wr_combine_df)\n",
    "\n",
    "wr_combine_plt = sns.pairplot(wr_combine_df)\n",
    "plt.savefig('plots/wr_combine_pairplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Dataset\n",
    "df = pd.read_csv('data/master_df.csv')\n",
    "\n",
    "# Separate Datasets by Position\n",
    "tes = df[df['Position'] == 'TE']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = StandardScaler()\n",
    "te_combine_df = tes[['Ht','Wt','40yd','Vertical','Bench','BroadJump','3Cone','Shuttle','Combine_Year','Fantasy_PPR']]\n",
    "#te_combine_df = te_combine_df.dropna()\n",
    "te_combine_df.replace(0, np.nan, inplace=True)\n",
    "te_combine_df = te_combine_df.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "model.fit(te_combine_df)\n",
    "\n",
    "te_combine_plt = sns.pairplot(te_combine_df)\n",
    "plt.savefig('plots/te_combine_pairplot.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_reduced_df.to_csv('data/qb_std_stats.csv')\n",
    "rb_reduced_df.to_csv('data/rb_std_stats.csv')\n",
    "wr_reduced_df.to_csv('data/wr_std_stats.csv')\n",
    "te_reduced_df.to_csv('data/te_std_stats.csv')\n",
    "qb_combine_df.to_csv('data/qb_combine_stats.csv')\n",
    "rb_combine_df.to_csv('data/rb_combine_stats.csv')\n",
    "wr_combine_df.to_csv('data/wr_combine_stats.csv')\n",
    "te_combine_df.to_csv('data/te_combine_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_reduced_df_no_1ds = qbs[['Age','Passing_TD%','Passing_Int%','Passing_Lng','Passing_Y/A','Passing_AY/A','Passing_Y/C','Passing_Sk','Passing_Sk%','Passing_NY/A','Passing_ANY/A','Rushing_Lng','Rushing_Y/A_y','Fantasy_PPR']]\n",
    "qb_reduced_df_no_1ds.to_csv('data/qb_std_stats_no_1ds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/master_df.csv')\n",
    "arod_example_lag_data = df[df['Player'] == 'Aaron Rodgers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_year_avg(df, row, param):\n",
    "    if row['Year'] - 3 >= 2012:\n",
    "        player_df = df[df['Player'] == row['Player']]\n",
    "        three_year_data = player_df[(player_df['Year'] >= (row['Year'] - 3)) & (player_df['Year'] <= (row['Year']-1))]\n",
    "        return three_year_data[param].mean()\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "def three_year_stddev(df, row, param):\n",
    "    if row['Year'] - 3 >= 2012:\n",
    "        player_df = df[df['Player'] == row['Player']]\n",
    "        three_year_data = player_df[(player_df['Year'] >= (row['Year'] - 3)) & (player_df['Year'] <= (row['Year']-1))]\n",
    "        return three_year_data[param].std()\n",
    "    else:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing 3 yr functions on one player\n",
    "arod_example_lag_data['3Year_lagging_avg'] = arod_example_lag_data.apply(lambda row: three_year_avg(arod_example_lag_data,row),axis=1)\n",
    "arod_example_lag_data[['Year','Fantasy_PPR','3Year_lagging_avg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing 3 yr functions on full datadrame\n",
    "df = pd.read_csv('data/master_df.csv')\n",
    "qbs = df[df['Position'] == \"QB\"]\n",
    "qbs['3Year_lagging_avg'] = qbs.apply(lambda row: three_year_avg(qbs,row),axis=1)\n",
    "qbs[qbs['Player'] == 'Tom Brady']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply 3 trailing year PPR avg and std dev for each player\n",
    "df = pd.read_csv('data/master_df.csv')\n",
    "df['3PriorYear_Avg_PPR'] = df.apply(lambda row: three_year_avg(df,row, 'Fantasy_PPR'),axis=1)\n",
    "df['3PriorYear_StdDev_PPR'] = df.apply(lambda row: three_year_stddev(df,row, 'Fantasy_PPR'),axis=1)\n",
    "df.to_csv('data/master_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/master_df_w_2022.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_adv_accuracy = pd.read_csv('data/pass_adv_accuracy.csv')\n",
    "pass_adv_air_yards = pd.read_csv('data/pass_adv_air_yards.csv')\n",
    "pass_adv_play_type = pd.read_csv('data/pass_adv_play_type.csv')\n",
    "pass_adv_pressure = pd.read_csv('data/pass_adv_pressure.csv')\n",
    "rush_adv = pd.read_csv('data/rush_adv.csv')\n",
    "rec_adv = pd.read_csv('data/rec_adv.csv')\n",
    "\n",
    "pass_adv_accuracy = pass_adv_accuracy[['Player','Bats','ThAwy','Spikes','Drops','Drop%','BadTh','Bad%','OnTgt','OnTgt%']]\n",
    "pass_adv_air_yards = pass_adv_air_yards[['Player','IAY','IAY/PA','CAY','CAY/Cmp','CAY/PA','YAC','YAC/Cmp']]\n",
    "pass_adv_play_type = pass_adv_play_type[['Player','RPO_Plays','RPO_Yds','RPO_PassAtt','RPO_PassYds','RPO_RushAtt','RPO_RushYds','PlayAction_PassAtt','PlayAction_PassYds']]\n",
    "pass_adv_pressure = pass_adv_pressure[['Player','Sk','PktTime','Bltz','Hrry','Hits','Prss','Prss%','Scrm','Yds/Scr']]\n",
    "rush_adv = rush_adv[['Player','Rushing_YBC','Rushing_YBC/Att','Rushing_YAC','Rushing_YAC/Att','Rushing_BrkTkl','Rushing_Att/Br']]\n",
    "rec_adv = rec_adv[['Player','Receiving_YBC','Receiving_YBC/R','Receiving_YAC','Receiving_YAC/R','Receiving_ADOT','Receiving_BrkTkl','Receiving_Rec/Br','Receiving_Drop','Receiving_Drop%','Receiving_Int','Receiving_Rat']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df_acc = df.merge(pass_adv_accuracy, how='left', on='Player')\n",
    "print(df_acc.shape)\n",
    "df_air = df_acc.merge(pass_adv_air_yards, how='left', on='Player')\n",
    "print(df_air.shape)\n",
    "df_play = df_air.merge(pass_adv_play_type, how='left', on='Player')\n",
    "print(df_play.shape)\n",
    "df_press = df_play.merge(pass_adv_pressure, how='left', on='Player')\n",
    "print(df_press.shape)\n",
    "df_rush_adv = df_press.merge(rush_adv, how='left', on='Player')\n",
    "print(df_rush_adv.shape)\n",
    "df_rec_adv = df_rush_adv.merge(rec_adv, how='left', on='Player')\n",
    "print(df_rec_adv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rec_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rec_adv[df_rec_adv['Player'] == 'Cooper Kupp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_adv_accuracy = pd.read_csv('data/pass_adv_accuracy_all.csv')\n",
    "pass_adv_air_yards = pd.read_csv('data/pass_adv_air_yards_all.csv')\n",
    "pass_adv_play_type = pd.read_csv('data/pass_adv_play_type_all.csv')\n",
    "pass_adv_pressure = pd.read_csv('data/pass_adv_pressure_all.csv')\n",
    "rush_adv = pd.read_csv('data/rush_adv_all.csv')\n",
    "rec_adv = pd.read_csv('data/rec_adv_all.csv')\n",
    "\n",
    "# Clean Player Name Column\n",
    "pass_adv_accuracy['Player'] = pass_adv_accuracy['Player'].str.strip('*+')\n",
    "pass_adv_accuracy['Drop%'] = pass_adv_accuracy['Drop%'].astype(str)\n",
    "pass_adv_accuracy['Drop%'] = pass_adv_accuracy['Drop%'].str.strip('%')\n",
    "pass_adv_accuracy['Drop%'] = pass_adv_accuracy['Drop%'].astype('float')\n",
    "pass_adv_accuracy['Bad%'] = pass_adv_accuracy['Bad%'].astype(str)\n",
    "pass_adv_accuracy['Bad%'] = pass_adv_accuracy['Bad%'].str.strip('%')\n",
    "pass_adv_accuracy['Bad%'] = pass_adv_accuracy['Bad%'].astype('float')\n",
    "pass_adv_accuracy['OnTgt%'] = pass_adv_accuracy['OnTgt%'].astype(str)\n",
    "pass_adv_accuracy['OnTgt%'] = pass_adv_accuracy['OnTgt%'].str.strip('%')\n",
    "pass_adv_accuracy['OnTgt%'] = pass_adv_accuracy['OnTgt%'].astype('float')\n",
    "\n",
    "# Clean Player Name Column\n",
    "pass_adv_air_yards['Player'] = pass_adv_air_yards['Player'].str.strip('*+')\n",
    "\n",
    "# Clean Player Name Column\n",
    "pass_adv_play_type['Player'] = pass_adv_play_type['Player'].str.strip('*+')\n",
    "\n",
    "# Clean Player Name Column\n",
    "pass_adv_pressure['Player'] = pass_adv_pressure['Player'].str.strip('*+')\n",
    "pass_adv_pressure['Prss%'] = pass_adv_pressure['Prss%'].astype(str)\n",
    "pass_adv_pressure['Prss%'] = pass_adv_pressure['Prss%'].str.strip('%')\n",
    "pass_adv_pressure['Prss%'] = pass_adv_pressure['Prss%'].astype('float')\n",
    "\n",
    "# Clean Player Name Column\n",
    "rush_adv['Player'] = rush_adv['Player'].str.strip('*+')\n",
    "\n",
    "# Clean Player Name Column\n",
    "rec_adv['Player'] = rec_adv['Player'].str.strip('*+')\n",
    "\n",
    "pass_adv_accuracy.to_csv('data/pass_adv_accuracy_all.csv')\n",
    "pass_adv_air_yards.to_csv('data/pass_adv_air_yards_all.csv')\n",
    "pass_adv_play_type.to_csv('data/pass_adv_play_type_all.csv')\n",
    "pass_adv_pressure.to_csv('data/pass_adv_pressure_all.csv')\n",
    "rush_adv.to_csv('data/rush_adv_all.csv')\n",
    "rec_adv.to_csv('data/rec_adv_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_adv_accuracy = pd.read_csv('data/pass_adv_accuracy_all.csv')\n",
    "pass_adv_air_yards = pd.read_csv('data/pass_adv_air_yards_all.csv')\n",
    "pass_adv_play_type = pd.read_csv('data/pass_adv_play_type_all.csv')\n",
    "pass_adv_pressure = pd.read_csv('data/pass_adv_pressure_all.csv')\n",
    "rush_adv = pd.read_csv('data/rush_adv_all.csv')\n",
    "rec_adv = pd.read_csv('data/rec_adv_all.csv')\n",
    "\n",
    "pass_adv_accuracy = pass_adv_accuracy[['Player','Year','Bats','ThAwy','Spikes','Drops','Drop%','BadTh','Bad%','OnTgt','OnTgt%']]\n",
    "pass_adv_air_yards = pass_adv_air_yards[['Player','Year','IAY','IAY/PA','CAY','CAY/Cmp','CAY/PA','YAC','YAC/Cmp']]\n",
    "pass_adv_play_type = pass_adv_play_type[['Player','Year','RPO_Plays','RPO_Yds','RPO_PassAtt','RPO_PassYds','RPO_RushAtt','RPO_RushYds','PlayAction_PassAtt','PlayAction_PassYds']]\n",
    "pass_adv_pressure = pass_adv_pressure[['Player','Year','Sk','PktTime','Bltz','Hrry','Hits','Prss','Prss%','Scrm','Yds/Scr']]\n",
    "rush_adv = rush_adv[['Player','Year','Rushing_YBC','Rushing_YBC/Att','Rushing_YAC','Rushing_YAC/Att','Rushing_BrkTkl','Rushing_Att/Br']]\n",
    "rec_adv = rec_adv[['Player','Year','Receiving_YBC','Receiving_YBC/R','Receiving_YAC','Receiving_YAC/R','Receiving_ADOT','Receiving_BrkTkl','Receiving_Rec/Br','Receiving_Drop','Receiving_Drop%','Receiving_Int','Receiving_Rat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df_acc = df.merge(pass_adv_accuracy, how='left', on=['Player','Year'])\n",
    "print(df_acc.shape)\n",
    "df_air = df_acc.merge(pass_adv_air_yards, how='left', on=['Player','Year'])\n",
    "print(df_air.shape)\n",
    "df_play = df_air.merge(pass_adv_play_type, how='left', on=['Player','Year'])\n",
    "print(df_play.shape)\n",
    "df_press = df_play.merge(pass_adv_pressure, how='left', on=['Player','Year'])\n",
    "print(df_press.shape)\n",
    "df_rush_adv = df_press.merge(rush_adv, how='left', on=['Player','Year'])\n",
    "print(df_rush_adv.shape)\n",
    "df_rec_adv = df_rush_adv.merge(rec_adv, how='left', on=['Player','Year'])\n",
    "print(df_rec_adv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rec_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rec_adv.to_csv('data/master_df_adv_w_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_adv = pd.read_csv('data/master_df_adv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_adv[master_df_adv['CombineYear'] == 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_adv_w_2022 = pd.read_csv('data/master_df_adv_w_2022.csv')\n",
    "master_df_adv_w_2022 = master_df_adv_w_2022.iloc[: , 2:]\n",
    "master_df_adv_w_2022 = master_df_adv_w_2022.drop('3PriorYear_Avg_PPR','3PriorYear_StdDev_PPR')\n",
    "\n",
    "three_year_avg_df = master_df_adv_w_2022\n",
    "list_of_unchanged_cols = ['Year','Rank','Player','Team','Position','Age','ADP','AvgMockDraftPosition','School','Ft','In','Ht']\n",
    "for col in master_df_adv_w_2022.columns:\n",
    "    print(col)\n",
    "    if col in list_of_unchanged_cols:\n",
    "        print('True')\n",
    "        three_year_avg_df[col] = master_df_adv_w_2022[col]\n",
    "    else:\n",
    "        print('False')\n",
    "        three_year_avg_df[col] = master_df_adv_w_2022.apply(lambda row: three_year_avg(master_df_adv_w_2022,row, col),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_year_avg_df['Fantasy_PPR'] = master_df_adv_w_2022['Fantasy_PPR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_year_avg_df['3YearPrior_Avg_PPR'] = three_year_avg_df.apply(lambda row: three_year_avg(master_df_adv_w_2022,row, 'Fantasy_PPR'),axis=1)\n",
    "three_year_avg_df['3YearPrior_StdDev_PPR'] = three_year_avg_df.apply(lambda row: three_year_stddev(master_df_adv_w_2022,row, 'Fantasy_PPR'),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_year_avg_df.loc[df[\"Year\"] == 2022, \"Fantasy_PPR\"] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fantasy_df_reduced = fantasy_df[['Player','Year', 'Fantasy_PPR']]\n",
    "fantasy_df_reduced['Year'] = fantasy_df_reduced['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in Fantasy points\n",
    "three_year_avg_df = three_year_avg_df.merge(fantasy_df_reduced, how='left', on=['Player','Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_year_avg_df = three_year_avg_df.drop('Fantasy_PPR_x', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_year_avg_df = three_year_avg_df.rename({'Fantasy_PPR_y': 'Fantasy_PPR'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_year_avg_df.to_csv('data/three_year_avg_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_2022 = pd.read_csv('data/pfr_combine_data_2000_thru_2022.csv')\n",
    "combine_2022 = combine_2022[combine_2022['Combine_Year'] == 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_adv_w_2022 = pd.read_csv('data/master_df_adv_w_2022.csv')\n",
    "three_year_avg_df_updated = pd.read_csv('data/three_year_avg_df.csv')\n",
    "three_year_avg_df_updated['Fantasy_PPR'] = master_df_adv_w_2022['Fantasy_PPR']\n",
    "three_year_avg_df_updated['3YearPrior_Avg_PPR'] = three_year_avg_df_updated.apply(lambda row: three_year_avg(master_df_adv_w_2022,row, 'Fantasy_PPR'),axis=1)\n",
    "three_year_avg_df_updated['3YearPrior_StdDev_PPR'] = three_year_avg_df_updated.apply(lambda row: three_year_stddev(master_df_adv_w_2022,row, 'Fantasy_PPR'),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_year_avg_df_updated.to_csv('data/three_year_avg_df_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
